Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker0/conf:/var/tmp/spark2.0hpcplatform/multicore/worker0/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=42315" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:42315" "--executor-id" "76" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619060716-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:43881"
========================================

Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/19 06:07:17 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 197711@mdc-ch1-cust4
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for TERM
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for HUP
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for INT
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/19 06:07:18 INFO SecurityManager: Changing view acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing view acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:18 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 83 ms (0 ms spent in bootstraps)
19/06/19 06:07:18 WARN SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/06/19 06:07:18 INFO SecurityManager: Changing view acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing view acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/19 06:07:18 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 9 ms (0 ms spent in bootstraps)
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:21 INFO DiskBlockManager: Created local directory at /tmp/spark-5186e9fe-5ff1-47e3-b4a5-9cdc43342499/executor-7f515190-0b1d-4a0c-8e45-fda68de8edff/blockmgr-668c16d7-34e9-44bd-9c54-ed62cf1b2514
19/06/19 06:07:21 INFO MemoryStore: MemoryStore started with capacity 4.1 GB
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:42315
19/06/19 06:07:21 INFO WorkerWatcher: Connecting to worker spark://Worker@mdc-ch1-cust4:43881
19/06/19 06:07:21 INFO WorkerWatcher: Successfully connected to spark://Worker@mdc-ch1-cust4:43881
19/06/19 06:07:21 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:43881 after 12 ms (0 ms spent in bootstraps)
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/06/19 06:07:21 INFO Executor: Starting executor ID 76 on host mdc-ch1-cust4
19/06/19 06:07:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41547.
19/06/19 06:07:22 INFO NettyBlockTransferService: Server created on mdc-ch1-cust4:41547
19/06/19 06:07:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/19 06:07:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(76, mdc-ch1-cust4, 41547, None)
19/06/19 06:07:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(76, mdc-ch1-cust4, 41547, None)
19/06/19 06:07:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(76, mdc-ch1-cust4, 41547, None)
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 208
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 209
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 210
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 211
19/06/19 06:07:22 INFO Executor: Running task 208.0 in stage 0.0 (TID 208)
19/06/19 06:07:22 INFO Executor: Running task 210.0 in stage 0.0 (TID 210)
19/06/19 06:07:22 INFO Executor: Running task 209.0 in stage 0.0 (TID 209)
19/06/19 06:07:22 INFO Executor: Running task 211.0 in stage 0.0 (TID 211)
19/06/19 06:07:22 INFO Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:42315/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1560949636224
19/06/19 06:07:22 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 3 ms (0 ms spent in bootstraps)
19/06/19 06:07:22 INFO Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:42315/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /tmp/spark-5186e9fe-5ff1-47e3-b4a5-9cdc43342499/executor-7f515190-0b1d-4a0c-8e45-fda68de8edff/spark-63901ff9-d0d0-43fe-a34f-15f1ac22e850/fetchFileTemp9140818025784801573.tmp
19/06/19 06:07:22 INFO Utils: Copying /tmp/spark-5186e9fe-5ff1-47e3-b4a5-9cdc43342499/executor-7f515190-0b1d-4a0c-8e45-fda68de8edff/spark-63901ff9-d0d0-43fe-a34f-15f1ac22e850/-11144796181560949636224_cache to /var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190619060716-0000/76/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/06/19 06:07:23 INFO Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190619060716-0000/76/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/06/19 06:07:23 INFO TorrentBroadcast: Started reading broadcast variable 1
19/06/19 06:07:23 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:44721 after 5 ms (0 ms spent in bootstraps)
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/06/19 06:07:23 INFO TorrentBroadcast: Reading broadcast variable 1 took 152 ms
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00005:19327352832+1073741824
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00005:20401094656+1073741824
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00005:21474836480+1073741824
19/06/19 06:07:23 INFO TorrentBroadcast: Started reading broadcast variable 0
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00005:22548578304+1073741824
19/06/19 06:07:23 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:36105 after 5 ms (0 ms spent in bootstraps)
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/06/19 06:07:23 INFO TorrentBroadcast: Reading broadcast variable 0 took 67 ms
19/06/19 06:07:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/06/19 06:08:33 INFO ShuffleExternalSorter: Thread 90 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:40 INFO ShuffleExternalSorter: Thread 92 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:42 INFO ShuffleExternalSorter: Thread 91 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:43 INFO ShuffleExternalSorter: Thread 89 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:10:16 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/06/19 06:10:16 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
