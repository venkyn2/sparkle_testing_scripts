Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker0/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker0/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=35591" "-Dspark.network.timeout=40000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35591" "--executor-id" "43" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190620092631-0011" "--worker-url" "spark://Worker@mdc-ch1-cust4:42841"
========================================

19/06/20 09:26:32 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 90440@mdc-ch1-cust4
19/06/20 09:26:32 INFO util.SignalUtils: Registered signal handler for TERM
19/06/20 09:26:32 INFO util.SignalUtils: Registered signal handler for HUP
19/06/20 09:26:32 INFO util.SignalUtils: Registered signal handler for INT
19/06/20 09:26:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/20 09:26:32 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/06/20 09:26:32 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/06/20 09:26:32 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/20 09:26:32 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/20 09:26:32 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/20 09:26:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:35591 after 46 ms (0 ms spent in bootstraps)
19/06/20 09:26:32 WARN spark.SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/06/20 09:26:32 WARN spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
19/06/20 09:26:32 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/06/20 09:26:32 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/06/20 09:26:32 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/20 09:26:32 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/20 09:26:32 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:35591 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO storage.DiskBlockManager: Created local directory at /data/spark-b3596b9a-018c-4388-a638-29ace3832afe/executor-0d3bd474-b425-48f6-977c-c7e6b9cdf15c/blockmgr-af1cc42a-da6f-4225-9500-4e73efc42b45
19/06/20 09:26:33 INFO memory.MemoryStore: MemoryStore started with capacity 4.1 GB
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35591
19/06/20 09:26:33 INFO worker.WorkerWatcher: Connecting to worker spark://Worker@mdc-ch1-cust4:42841
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:42841 after 2 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO worker.WorkerWatcher: Successfully connected to spark://Worker@mdc-ch1-cust4:42841
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
19/06/20 09:26:33 INFO executor.Executor: Starting executor ID 43 on host mdc-ch1-cust4
19/06/20 09:26:33 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36615.
19/06/20 09:26:33 INFO netty.NettyBlockTransferService: Server created on mdc-ch1-cust4:36615
19/06/20 09:26:33 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/20 09:26:33 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(43, mdc-ch1-cust4, 36615, None)
19/06/20 09:26:33 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(43, mdc-ch1-cust4, 36615, None)
19/06/20 09:26:33 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(43, mdc-ch1-cust4, 36615, None)
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 60
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 106
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 152
19/06/20 09:26:33 INFO executor.Executor: Running task 60.0 in stage 0.0 (TID 60)
19/06/20 09:26:33 INFO executor.Executor: Running task 106.0 in stage 0.0 (TID 106)
19/06/20 09:26:33 INFO executor.Executor: Running task 14.0 in stage 0.0 (TID 14)
19/06/20 09:26:33 INFO executor.Executor: Running task 152.0 in stage 0.0 (TID 152)
19/06/20 09:26:33 INFO executor.Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:35591/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1561047991720
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:35591 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO util.Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:35591/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /data/spark-b3596b9a-018c-4388-a638-29ace3832afe/executor-0d3bd474-b425-48f6-977c-c7e6b9cdf15c/spark-1586f700-8523-4665-9bee-2f293998e8a3/fetchFileTemp5138926960845745592.tmp
19/06/20 09:26:33 INFO util.Utils: Copying /data/spark-b3596b9a-018c-4388-a638-29ace3832afe/executor-0d3bd474-b425-48f6-977c-c7e6b9cdf15c/spark-1586f700-8523-4665-9bee-2f293998e8a3/-339060041561047991720_cache to /var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190620092631-0011/43/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/06/20 09:26:33 INFO executor.Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190620092631-0011/43/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/06/20 09:26:33 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:39129 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/06/20 09:26:33 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 70 ms
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00000:64424509440+1073741824
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00002:2147483648+1073741824
19/06/20 09:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00000:15032385536+1073741824
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00001:33285996544+1073741824
19/06/20 09:26:34 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:39889 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/06/20 09:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 33 ms
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/06/20 09:42:43 INFO sort.ShuffleExternalSorter: Thread 72 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:43:13 INFO sort.ShuffleExternalSorter: Thread 71 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:44:36 INFO executor.Executor: Finished task 106.0 in stage 0.0 (TID 106). 2958 bytes result sent to driver
19/06/20 09:44:36 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1054
19/06/20 09:44:36 INFO executor.Executor: Running task 1054.0 in stage 0.0 (TID 1054)
19/06/20 09:44:36 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00014:4294967296+1073741824
19/06/20 09:46:06 INFO executor.Executor: Finished task 152.0 in stage 0.0 (TID 152). 2958 bytes result sent to driver
19/06/20 09:46:06 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1141
19/06/20 09:46:06 INFO executor.Executor: Running task 1141.0 in stage 0.0 (TID 1141)
19/06/20 09:46:06 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00015:17179869184+1073741824
19/06/20 09:53:22 INFO sort.ShuffleExternalSorter: Thread 71 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:55:59 INFO executor.Executor: Finished task 1054.0 in stage 0.0 (TID 1054). 2958 bytes result sent to driver
19/06/20 09:55:59 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1558
19/06/20 09:55:59 INFO executor.Executor: Running task 1558.0 in stage 0.0 (TID 1558)
19/06/20 09:55:59 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00020:62277025792+1073741824
19/06/20 09:57:33 INFO sort.ShuffleExternalSorter: Thread 69 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:59:10 INFO sort.ShuffleExternalSorter: Thread 70 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 10:01:01 INFO sort.ShuffleExternalSorter: Thread 72 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 10:01:14 INFO executor.Executor: Finished task 14.0 in stage 0.0 (TID 14). 2958 bytes result sent to driver
19/06/20 10:01:41 INFO executor.Executor: Finished task 1141.0 in stage 0.0 (TID 1141). 2958 bytes result sent to driver
19/06/20 10:01:44 INFO executor.Executor: Finished task 60.0 in stage 0.0 (TID 60). 2958 bytes result sent to driver
19/06/20 10:04:01 INFO executor.Executor: Finished task 1558.0 in stage 0.0 (TID 1558). 2872 bytes result sent to driver
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1918
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2018
19/06/20 10:14:31 INFO executor.Executor: Running task 43.0 in stage 1.0 (TID 1918)
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2118
19/06/20 10:14:31 INFO executor.Executor: Running task 143.0 in stage 1.0 (TID 2018)
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2218
19/06/20 10:14:31 INFO executor.Executor: Running task 343.0 in stage 1.0 (TID 2218)
19/06/20 10:14:31 INFO executor.Executor: Running task 243.0 in stage 1.0 (TID 2118)
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
19/06/20 10:14:31 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
19/06/20 10:14:31 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 25.0 KB, free 4.1 GB)
19/06/20 10:14:31 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 7 ms
19/06/20 10:14:31 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 69.4 KB, free 4.1 GB)
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@mdc-ch1-cust4.mdc.ext.hpe.com:35591)
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Got the output locations
19/06/20 10:14:31 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:14:31 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:14:31 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:44295 after 2 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:37193 after 2 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:35497 after 3 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:36127 after 5 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:40573 after 4 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:37961 after 3 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:35655 after 7 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:40777 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:38137 after 21 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:33347 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:40923 after 6 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:46333 after 9 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:42033 after 7 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:32975 after 8 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Started 7 remote fetches in 73 ms
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:35265 after 9 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:39023 after 9 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:40437 after 10 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:39819 after 10 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:36557 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:45427 after 15 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:45911 after 26 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:33457 after 24 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:34241 after 19 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 132 ms
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:37195 after 17 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:32855 after 0 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 140 ms
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:41699 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:40803 after 3 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:43867 after 39 ms (0 ms spent in bootstraps)
19/06/20 10:14:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:39285 after 1006 ms (0 ms spent in bootstraps)
19/06/20 10:14:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:43327 after 26 ms (0 ms spent in bootstraps)
19/06/20 10:14:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:38665 after 27 ms (0 ms spent in bootstraps)
19/06/20 10:14:33 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 1155 ms
19/06/20 10:14:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:36153 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:33659 after 1053 ms (0 ms spent in bootstraps)
19/06/20 10:14:34 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:39789 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:14:35 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:46487 after 90 ms (0 ms spent in bootstraps)
19/06/20 10:14:35 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:33717 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:14:35 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:43903 after 29 ms (0 ms spent in bootstraps)
19/06/20 10:14:36 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:41811 after 49 ms (0 ms spent in bootstraps)
19/06/20 10:14:41 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:45875 after 50 ms (0 ms spent in bootstraps)
19/06/20 10:14:41 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:33833 after 67 ms (0 ms spent in bootstraps)
19/06/20 10:14:42 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:45965 after 0 ms (0 ms spent in bootstraps)
19/06/20 10:14:42 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:41545 after 35 ms (0 ms spent in bootstraps)
19/06/20 10:14:42 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:33807 after 19 ms (0 ms spent in bootstraps)
19/06/20 10:14:45 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:35275 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:48 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:41657 after 43 ms (0 ms spent in bootstraps)
19/06/20 10:14:49 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:33113 after 20 ms (0 ms spent in bootstraps)
19/06/20 10:14:49 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:42735 after 46 ms (0 ms spent in bootstraps)
19/06/20 10:14:50 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:37727 after 17 ms (0 ms spent in bootstraps)
19/06/20 10:14:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:38259 after 48 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:36079 after 18 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:46775 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:37233 after 100 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:42161 after 37 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:46601 after 43 ms (0 ms spent in bootstraps)
19/06/20 10:14:54 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:39023 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:54 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:43039 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:14:54 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:45869 after 45 ms (0 ms spent in bootstraps)
19/06/20 10:14:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:42325 after 78 ms (0 ms spent in bootstraps)
19/06/20 10:14:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:35209 after 39 ms (0 ms spent in bootstraps)
19/06/20 10:14:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:35145 after 2 ms (0 ms spent in bootstraps)
19/06/20 10:14:56 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:39883 after 98 ms (0 ms spent in bootstraps)
19/06/20 10:14:56 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:36525 after 93 ms (0 ms spent in bootstraps)
19/06/20 10:14:57 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:39063 after 9 ms (0 ms spent in bootstraps)
19/06/20 10:14:58 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:33191 after 17 ms (0 ms spent in bootstraps)
19/06/20 10:14:58 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:43487 after 84 ms (0 ms spent in bootstraps)
19/06/20 10:14:58 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:40313 after 36 ms (0 ms spent in bootstraps)
19/06/20 10:14:59 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:42171 after 80 ms (0 ms spent in bootstraps)
19/06/20 10:15:00 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:38379 after 65 ms (0 ms spent in bootstraps)
19/06/20 10:15:02 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:42049 after 75 ms (0 ms spent in bootstraps)
19/06/20 10:15:06 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:32871 after 19 ms (0 ms spent in bootstraps)
19/06/20 10:15:06 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:38915 after 24 ms (0 ms spent in bootstraps)
19/06/20 10:15:07 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:38193 after 21 ms (0 ms spent in bootstraps)
19/06/20 10:15:09 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:44941 after 93 ms (0 ms spent in bootstraps)
19/06/20 10:15:10 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:34507 after 50 ms (0 ms spent in bootstraps)
19/06/20 10:15:10 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:43493 after 56 ms (0 ms spent in bootstraps)
19/06/20 10:15:12 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:33877 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:15:12 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:41251 after 65 ms (0 ms spent in bootstraps)
19/06/20 10:15:14 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:37187 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:15:14 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:37741 after 61 ms (0 ms spent in bootstraps)
19/06/20 10:15:15 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:32905 after 6 ms (0 ms spent in bootstraps)
19/06/20 10:15:17 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:41471 after 103 ms (0 ms spent in bootstraps)
19/06/20 10:15:19 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:33351 after 52 ms (0 ms spent in bootstraps)
19/06/20 10:15:23 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:38911 after 92 ms (0 ms spent in bootstraps)
19/06/20 10:15:23 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:43651 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:15:24 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:42049 after 80 ms (0 ms spent in bootstraps)
19/06/20 10:15:25 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:35777 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:15:27 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:42461 after 41 ms (0 ms spent in bootstraps)
19/06/20 10:15:29 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:38551 after 24 ms (0 ms spent in bootstraps)
19/06/20 10:15:29 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:37161 after 71 ms (0 ms spent in bootstraps)
19/06/20 10:15:30 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:37409 after 1493 ms (0 ms spent in bootstraps)
19/06/20 10:15:31 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:45039 after 50 ms (0 ms spent in bootstraps)
19/06/20 10:15:35 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:34997 after 42 ms (0 ms spent in bootstraps)
19/06/20 10:15:36 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:46747 after 4 ms (0 ms spent in bootstraps)
19/06/20 10:16:02 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:41651 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:16:02 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:43807 after 17 ms (0 ms spent in bootstraps)
19/06/20 10:16:03 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:33421 after 17 ms (0 ms spent in bootstraps)
19/06/20 10:16:04 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:40783 after 23 ms (0 ms spent in bootstraps)
19/06/20 10:16:18 INFO collection.ExternalSorter: Thread 95 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:16:18 INFO collection.ExternalSorter: Thread 93 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:16:40 INFO collection.ExternalSorter: Thread 94 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:16:48 INFO collection.ExternalSorter: Thread 92 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:19:47 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:46425 after 32 ms (0 ms spent in bootstraps)
19/06/20 10:21:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:21:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:21:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:21:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:22:12 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000143_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000143
19/06/20 10:22:12 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000143_0: Committed
19/06/20 10:22:12 INFO executor.Executor: Finished task 143.0 in stage 1.0 (TID 2018). 1342 bytes result sent to driver
19/06/20 10:22:12 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2288
19/06/20 10:22:12 INFO executor.Executor: Running task 413.0 in stage 1.0 (TID 2288)
19/06/20 10:22:13 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:22:13 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 3 ms
19/06/20 10:22:16 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000043_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000043
19/06/20 10:22:16 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000043_0: Committed
19/06/20 10:22:16 INFO executor.Executor: Finished task 43.0 in stage 1.0 (TID 1918). 1299 bytes result sent to driver
19/06/20 10:22:16 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2289
19/06/20 10:22:16 INFO executor.Executor: Running task 414.0 in stage 1.0 (TID 2289)
19/06/20 10:22:16 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:22:16 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 34 ms
19/06/20 10:22:25 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:22:25 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:23:27 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073745949_5125
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:23:27 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:23:27 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000243_0 aborted.
19/06/20 10:23:27 ERROR executor.Executor: Exception in task 243.0 in stage 1.0 (TID 2118)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:23:27 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2343
19/06/20 10:23:27 INFO executor.Executor: Running task 468.0 in stage 1.0 (TID 2343)
19/06/20 10:23:27 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:23:27 INFO storage.ShuffleBlockFetcherIterator: Started 8 remote fetches in 16 ms
19/06/20 10:23:32 INFO collection.ExternalSorter: Thread 93 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:23:54 INFO collection.ExternalSorter: Thread 92 spilling in-memory map of 1294.1 MB to disk (1 time so far)
19/06/20 10:24:49 INFO collection.ExternalSorter: Thread 94 spilling in-memory map of 810.3 MB to disk (1 time so far)
19/06/20 10:26:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:26:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:27:23 WARN hdfs.DFSClient: DataStreamer Exception
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:508)
19/06/20 10:27:23 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:27:23 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000343_0 aborted.
19/06/20 10:27:23 ERROR executor.Executor: Exception in task 343.0 in stage 1.0 (TID 2218)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:27:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2634
19/06/20 10:27:23 INFO executor.Executor: Running task 728.0 in stage 1.0 (TID 2634)
19/06/20 10:27:23 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:27:23 INFO storage.ShuffleBlockFetcherIterator: Started 7 remote fetches in 3 ms
19/06/20 10:30:07 INFO collection.ExternalSorter: Thread 95 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:31:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:57 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000414_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000414
19/06/20 10:31:57 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000414_0: Committed
19/06/20 10:31:57 INFO executor.Executor: Finished task 414.0 in stage 1.0 (TID 2289). 1299 bytes result sent to driver
19/06/20 10:31:57 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2691
19/06/20 10:31:57 INFO executor.Executor: Running task 777.0 in stage 1.0 (TID 2691)
19/06/20 10:31:57 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:31:57 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 2 ms
19/06/20 10:32:23 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000413_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000413
19/06/20 10:32:23 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000413_0: Committed
19/06/20 10:32:23 INFO executor.Executor: Finished task 413.0 in stage 1.0 (TID 2288). 1299 bytes result sent to driver
19/06/20 10:32:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2698
19/06/20 10:32:23 INFO executor.Executor: Running task 782.0 in stage 1.0 (TID 2698)
19/06/20 10:32:23 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:32:23 INFO storage.ShuffleBlockFetcherIterator: Started 11 remote fetches in 2 ms
19/06/20 10:33:49 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073746338_5514
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:33:49 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:33:49 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000468_0 aborted.
19/06/20 10:33:49 ERROR executor.Executor: Exception in task 468.0 in stage 1.0 (TID 2343)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:33:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2766
19/06/20 10:33:49 INFO executor.Executor: Running task 846.0 in stage 1.0 (TID 2766)
19/06/20 10:33:49 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:33:49 INFO storage.ShuffleBlockFetcherIterator: Started 7 remote fetches in 3 ms
19/06/20 10:34:08 INFO collection.ExternalSorter: Thread 92 spilling in-memory map of 1597.4 MB to disk (1 time so far)
19/06/20 10:35:05 INFO collection.ExternalSorter: Thread 94 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:35:06 INFO collection.ExternalSorter: Thread 93 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:35:19 INFO collection.ExternalSorter: Thread 95 spilling in-memory map of 765.4 MB to disk (2 times so far)
19/06/20 10:36:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:36:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:38:09 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073746653_5829
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:38:09 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:38:09 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000728_0 aborted.
19/06/20 10:38:09 ERROR executor.Executor: Exception in task 728.0 in stage 1.0 (TID 2634)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:38:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3029
19/06/20 10:38:09 INFO executor.Executor: Running task 763.1 in stage 1.0 (TID 3029)
19/06/20 10:38:09 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:38:09 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 3 ms
19/06/20 10:40:01 INFO collection.ExternalSorter: Thread 95 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:40:16 INFO collection.ExternalSorter: Thread 93 spilling in-memory map of 765.4 MB to disk (2 times so far)
19/06/20 10:41:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:41:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:41:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:41:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:42:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:42:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:42:25 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000777_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000777
19/06/20 10:42:25 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000777_0: Committed
19/06/20 10:42:25 INFO executor.Executor: Finished task 777.0 in stage 1.0 (TID 2691). 1299 bytes result sent to driver
19/06/20 10:42:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3111
19/06/20 10:42:25 INFO executor.Executor: Running task 1155.0 in stage 1.0 (TID 3111)
19/06/20 10:42:25 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:42:25 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 15 ms
19/06/20 10:42:27 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000782_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000782
19/06/20 10:42:27 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000782_0: Committed
19/06/20 10:42:27 INFO executor.Executor: Finished task 782.0 in stage 1.0 (TID 2698). 1299 bytes result sent to driver
19/06/20 10:42:27 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3112
19/06/20 10:42:27 INFO executor.Executor: Running task 1156.0 in stage 1.0 (TID 3112)
19/06/20 10:42:27 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:42:27 INFO storage.ShuffleBlockFetcherIterator: Started 7 remote fetches in 1 ms
19/06/20 10:43:14 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000846_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000846
19/06/20 10:43:14 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000846_0: Committed
19/06/20 10:43:14 INFO executor.Executor: Finished task 846.0 in stage 1.0 (TID 2766). 1342 bytes result sent to driver
19/06/20 10:43:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3130
19/06/20 10:43:14 INFO executor.Executor: Running task 1173.0 in stage 1.0 (TID 3130)
19/06/20 10:43:14 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:43:14 INFO storage.ShuffleBlockFetcherIterator: Started 13 remote fetches in 4 ms
19/06/20 10:43:52 INFO collection.ExternalSorter: Thread 166 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:43:57 INFO collection.ExternalSorter: Thread 92 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:44:51 INFO collection.ExternalSorter: Thread 94 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:45:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:45:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:46:42 WARN hdfs.DFSClient: DataStreamer Exception
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:508)
19/06/20 10:46:42 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:46:42 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000763_1 aborted.
19/06/20 10:46:42 ERROR executor.Executor: Exception in task 763.1 in stage 1.0 (TID 3029)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:46:42 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3330
19/06/20 10:46:42 INFO executor.Executor: Running task 1358.0 in stage 1.0 (TID 3330)
19/06/20 10:46:42 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:46:42 INFO storage.ShuffleBlockFetcherIterator: Started 8 remote fetches in 9 ms
19/06/20 10:48:49 INFO collection.ExternalSorter: Thread 95 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:51:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:51:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:53:00 WARN hdfs.DFSClient: Slow ReadProcessor read fields took 57949ms (threshold=30000ms); ack: seqno: 3072 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK]]
19/06/20 10:53:30 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001156_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001156
19/06/20 10:53:30 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001156_0: Committed
19/06/20 10:53:30 INFO executor.Executor: Finished task 1156.0 in stage 1.0 (TID 3112). 1299 bytes result sent to driver
19/06/20 10:53:30 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3528
19/06/20 10:53:30 INFO executor.Executor: Running task 1536.0 in stage 1.0 (TID 3528)
19/06/20 10:53:30 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:53:30 INFO storage.ShuffleBlockFetcherIterator: Started 11 remote fetches in 13 ms
19/06/20 10:53:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:53:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:53:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:53:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:55:03 WARN hdfs.DFSClient: Slow ReadProcessor read fields took 36232ms (threshold=30000ms); ack: seqno: 8365 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK]]
19/06/20 10:55:04 INFO collection.ExternalSorter: Thread 166 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:55:33 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001155_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001155
19/06/20 10:55:33 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001155_0: Committed
19/06/20 10:55:33 INFO executor.Executor: Finished task 1155.0 in stage 1.0 (TID 3111). 1299 bytes result sent to driver
19/06/20 10:55:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3607
19/06/20 10:55:33 INFO executor.Executor: Running task 1613.0 in stage 1.0 (TID 3607)
19/06/20 10:55:33 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:55:33 INFO storage.ShuffleBlockFetcherIterator: Started 8 remote fetches in 2 ms
19/06/20 10:55:37 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001173_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001173
19/06/20 10:55:37 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001173_0: Committed
19/06/20 10:55:37 INFO executor.Executor: Finished task 1173.0 in stage 1.0 (TID 3130). 1299 bytes result sent to driver
19/06/20 10:55:37 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3611
19/06/20 10:55:37 INFO executor.Executor: Running task 1617.0 in stage 1.0 (TID 3611)
19/06/20 10:55:37 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:55:37 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 2 ms
19/06/20 10:57:15 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:57:15 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:57:34 INFO collection.ExternalSorter: Thread 94 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:57:34 INFO collection.ExternalSorter: Thread 92 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:58:36 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001358_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001358
19/06/20 10:58:36 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001358_0: Committed
19/06/20 10:58:36 INFO executor.Executor: Finished task 1358.0 in stage 1.0 (TID 3330). 1342 bytes result sent to driver
19/06/20 10:58:36 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3759
19/06/20 10:58:36 INFO executor.Executor: Running task 1753.0 in stage 1.0 (TID 3759)
19/06/20 10:58:36 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 7 local blocks and 1868 remote blocks
19/06/20 10:58:36 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 11 ms
19/06/20 11:00:16 INFO collection.ExternalSorter: Thread 95 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 11:02:48 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:02:48 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:03:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:03:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:00 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001536_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001536
19/06/20 11:04:00 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001536_0: Committed
19/06/20 11:04:00 INFO executor.Executor: Finished task 1536.0 in stage 1.0 (TID 3528). 1342 bytes result sent to driver
19/06/20 11:04:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:38 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001613_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001613
19/06/20 11:04:38 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001613_0: Committed
19/06/20 11:04:38 INFO executor.Executor: Finished task 1613.0 in stage 1.0 (TID 3607). 1299 bytes result sent to driver
19/06/20 11:04:54 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001617_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001617
19/06/20 11:04:54 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001617_0: Committed
19/06/20 11:04:54 INFO executor.Executor: Finished task 1617.0 in stage 1.0 (TID 3611). 1299 bytes result sent to driver
19/06/20 11:05:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:05:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:05:15 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001753_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001753
19/06/20 11:05:15 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001753_0: Committed
19/06/20 11:05:15 INFO executor.Executor: Finished task 1753.0 in stage 1.0 (TID 3759). 1299 bytes result sent to driver
19/06/20 11:08:45 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/06/20 11:08:45 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
