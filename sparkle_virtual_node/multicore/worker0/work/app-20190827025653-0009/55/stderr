Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker0/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker0/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx5120M" "-Dspark.driver.port=37373" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:37373" "--executor-id" "55" "--hostname" "10.1.1.4" "--cores" "4" "--app-id" "app-20190827025653-0009" "--worker-url" "spark://Worker@10.1.1.4:46217"
========================================

19/08/27 02:56:54 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 8366@mdc-ch1-cust4
19/08/27 02:56:54 INFO util.SignalUtils: Registered signal handler for TERM
19/08/27 02:56:54 INFO util.SignalUtils: Registered signal handler for HUP
19/08/27 02:56:54 INFO util.SignalUtils: Registered signal handler for INT
19/08/27 02:56:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/27 02:56:54 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/08/27 02:56:54 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/08/27 02:56:54 INFO spark.SecurityManager: Changing view acls groups to: 
19/08/27 02:56:54 INFO spark.SecurityManager: Changing modify acls groups to: 
19/08/27 02:56:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/08/27 02:56:54 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:37373 after 46 ms (0 ms spent in bootstraps)
19/08/27 02:56:54 WARN spark.SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/08/27 02:56:54 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/08/27 02:56:54 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/08/27 02:56:54 INFO spark.SecurityManager: Changing view acls groups to: 
19/08/27 02:56:54 INFO spark.SecurityManager: Changing modify acls groups to: 
19/08/27 02:56:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/08/27 02:56:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:37373 after 1 ms (0 ms spent in bootstraps)
19/08/27 02:56:55 INFO storage.DiskBlockManager: Created local directory at /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-66751eb1-13a7-42c0-bd30-69f88d907032/blockmgr-4ee85bfc-786f-4781-8b1d-5632d68817dd
19/08/27 02:56:55 INFO memory.MemoryStore: MemoryStore started with capacity 2.5 GB
19/08/27 02:56:55 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:37373
19/08/27 02:56:55 INFO worker.WorkerWatcher: Connecting to worker spark://Worker@10.1.1.4:46217
19/08/27 02:56:55 INFO client.TransportClientFactory: Successfully created connection to /10.1.1.4:46217 after 2 ms (0 ms spent in bootstraps)
19/08/27 02:56:55 INFO worker.WorkerWatcher: Successfully connected to spark://Worker@10.1.1.4:46217
19/08/27 02:56:55 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
19/08/27 02:56:55 INFO executor.Executor: Starting executor ID 55 on host 10.1.1.4
19/08/27 02:56:55 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38271.
19/08/27 02:56:55 INFO netty.NettyBlockTransferService: Server created on 10.1.1.4:38271
19/08/27 02:56:55 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/27 02:56:55 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(55, 10.1.1.4, 38271, None)
19/08/27 02:56:55 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(55, 10.1.1.4, 38271, None)
19/08/27 02:56:55 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(55, 10.1.1.4, 38271, None)
19/08/27 02:56:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 12
19/08/27 02:56:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 13
19/08/27 02:56:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
19/08/27 02:56:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 15
19/08/27 02:56:55 INFO executor.Executor: Running task 15.0 in stage 0.0 (TID 15)
19/08/27 02:56:55 INFO executor.Executor: Running task 14.0 in stage 0.0 (TID 14)
19/08/27 02:56:55 INFO executor.Executor: Running task 13.0 in stage 0.0 (TID 13)
19/08/27 02:56:55 INFO executor.Executor: Running task 12.0 in stage 0.0 (TID 12)
19/08/27 02:56:55 INFO executor.Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:37373/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1566899813727
19/08/27 02:56:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:37373 after 1 ms (0 ms spent in bootstraps)
19/08/27 02:56:55 INFO util.Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:37373/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-66751eb1-13a7-42c0-bd30-69f88d907032/spark-8cb29be8-feda-4a71-9b8d-792c1c60e329/fetchFileTemp3186348895636648949.tmp
19/08/27 02:56:55 INFO util.Utils: Copying /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-66751eb1-13a7-42c0-bd30-69f88d907032/spark-8cb29be8-feda-4a71-9b8d-792c1c60e329/14046417081566899813727_cache to /var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190827025653-0009/55/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/08/27 02:56:55 INFO executor.Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190827025653-0009/55/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/08/27 02:56:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
19/08/27 02:56:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:34119 after 1 ms (0 ms spent in bootstraps)
19/08/27 02:56:55 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.4 KB, free 2.5 GB)
19/08/27 02:56:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 65 ms
19/08/27 02:56:56 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 68.5 KB, free 2.5 GB)
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 02:56:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/27 03:19:18 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190827025654_0001_r_000013_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven3000G/HSsort-input/_temporary/0/task_20190827025654_0001_r_000013
19/08/27 03:19:18 INFO mapred.SparkHadoopMapRedUtil: attempt_20190827025654_0001_r_000013_0: Committed
19/08/27 03:19:18 INFO executor.Executor: Finished task 13.0 in stage 0.0 (TID 13). 912 bytes result sent to driver
19/08/27 03:19:21 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190827025654_0001_r_000015_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven3000G/HSsort-input/_temporary/0/task_20190827025654_0001_r_000015
19/08/27 03:19:21 INFO mapred.SparkHadoopMapRedUtil: attempt_20190827025654_0001_r_000015_0: Committed
19/08/27 03:19:21 INFO executor.Executor: Finished task 15.0 in stage 0.0 (TID 15). 869 bytes result sent to driver
19/08/27 03:19:25 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190827025654_0001_r_000014_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven3000G/HSsort-input/_temporary/0/task_20190827025654_0001_r_000014
19/08/27 03:19:25 INFO mapred.SparkHadoopMapRedUtil: attempt_20190827025654_0001_r_000014_0: Committed
19/08/27 03:19:25 INFO executor.Executor: Finished task 14.0 in stage 0.0 (TID 14). 869 bytes result sent to driver
19/08/27 03:19:26 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190827025654_0001_r_000012_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven3000G/HSsort-input/_temporary/0/task_20190827025654_0001_r_000012
19/08/27 03:19:26 INFO mapred.SparkHadoopMapRedUtil: attempt_20190827025654_0001_r_000012_0: Committed
19/08/27 03:19:26 INFO executor.Executor: Finished task 12.0 in stage 0.0 (TID 12). 869 bytes result sent to driver
19/08/27 03:26:44 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
tes result sent to driver
