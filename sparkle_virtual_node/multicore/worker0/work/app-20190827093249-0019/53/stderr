Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker0/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker0/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=44907" "-Dspark.network.timeout=40000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:44907" "--executor-id" "53" "--hostname" "10.1.1.4" "--cores" "4" "--app-id" "app-20190827093249-0019" "--worker-url" "spark://Worker@10.1.1.4:46217"
========================================

19/08/27 09:32:49 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 60783@mdc-ch1-cust4
19/08/27 09:32:49 INFO util.SignalUtils: Registered signal handler for TERM
19/08/27 09:32:49 INFO util.SignalUtils: Registered signal handler for HUP
19/08/27 09:32:49 INFO util.SignalUtils: Registered signal handler for INT
19/08/27 09:32:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/27 09:32:49 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/08/27 09:32:49 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/08/27 09:32:49 INFO spark.SecurityManager: Changing view acls groups to: 
19/08/27 09:32:49 INFO spark.SecurityManager: Changing modify acls groups to: 
19/08/27 09:32:49 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/08/27 09:32:50 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:44907 after 50 ms (0 ms spent in bootstraps)
19/08/27 09:32:50 WARN spark.SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/08/27 09:32:50 WARN spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
19/08/27 09:32:50 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/08/27 09:32:50 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/08/27 09:32:50 INFO spark.SecurityManager: Changing view acls groups to: 
19/08/27 09:32:50 INFO spark.SecurityManager: Changing modify acls groups to: 
19/08/27 09:32:50 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/08/27 09:32:50 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:44907 after 10 ms (0 ms spent in bootstraps)
19/08/27 09:32:50 INFO storage.DiskBlockManager: Created local directory at /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-ce79734d-94c1-4a73-a6c0-363277e7615c/blockmgr-368838d6-12b9-474b-982a-4e94e3e6beb2
19/08/27 09:32:50 INFO memory.MemoryStore: MemoryStore started with capacity 4.1 GB
19/08/27 09:32:50 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:44907
19/08/27 09:32:50 INFO worker.WorkerWatcher: Connecting to worker spark://Worker@10.1.1.4:46217
19/08/27 09:32:50 INFO client.TransportClientFactory: Successfully created connection to /10.1.1.4:46217 after 2 ms (0 ms spent in bootstraps)
19/08/27 09:32:50 INFO worker.WorkerWatcher: Successfully connected to spark://Worker@10.1.1.4:46217
19/08/27 09:32:50 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
19/08/27 09:32:50 INFO executor.Executor: Starting executor ID 53 on host 10.1.1.4
19/08/27 09:32:50 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43425.
19/08/27 09:32:50 INFO netty.NettyBlockTransferService: Server created on 10.1.1.4:43425
19/08/27 09:32:50 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/27 09:32:50 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(53, 10.1.1.4, 43425, None)
19/08/27 09:32:50 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(53, 10.1.1.4, 43425, None)
19/08/27 09:32:50 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(53, 10.1.1.4, 43425, None)
19/08/27 09:32:51 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 16
19/08/27 09:32:51 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 97
19/08/27 09:32:51 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 115
19/08/27 09:32:51 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 196
19/08/27 09:32:51 INFO executor.Executor: Running task 40.0 in stage 0.0 (TID 16)
19/08/27 09:32:51 INFO executor.Executor: Running task 939.0 in stage 0.0 (TID 97)
19/08/27 09:32:51 INFO executor.Executor: Running task 31.0 in stage 0.0 (TID 115)
19/08/27 09:32:51 INFO executor.Executor: Running task 133.0 in stage 0.0 (TID 196)
19/08/27 09:32:51 INFO executor.Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:44907/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1566923568972
19/08/27 09:32:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:44907 after 1 ms (0 ms spent in bootstraps)
19/08/27 09:32:51 INFO util.Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:44907/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-ce79734d-94c1-4a73-a6c0-363277e7615c/spark-a935ecb1-bc68-4c25-97e5-52d64b8f96f7/fetchFileTemp1225236025603209577.tmp
19/08/27 09:32:51 INFO util.Utils: Copying /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-ce79734d-94c1-4a73-a6c0-363277e7615c/spark-a935ecb1-bc68-4c25-97e5-52d64b8f96f7/18744607911566923568972_cache to /var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190827093249-0019/53/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/08/27 09:32:51 INFO executor.Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190827093249-0019/53/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/08/27 09:32:51 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
19/08/27 09:32:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:43649 after 1 ms (0 ms spent in bootstraps)
19/08/27 09:32:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/08/27 09:32:51 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 100 ms
19/08/27 09:32:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/08/27 09:32:51 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00024:28991029248+1073741824
19/08/27 09:32:51 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00003:20401094656+1073741824
19/08/27 09:32:51 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:33285996544+1073741824
19/08/27 09:32:51 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00001:2147483648+1073741824
19/08/27 09:32:51 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
19/08/27 09:32:51 INFO client.TransportClientFactory: Successfully created connection to /10.1.1.4:44329 after 1 ms (0 ms spent in bootstraps)
19/08/27 09:32:51 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/08/27 09:32:51 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 29 ms
19/08/27 09:32:51 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/08/27 09:32:52 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001
19/08/27 09:32:52 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:32:52 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 2151.617979373876 msec.
19/08/27 09:32:52 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024
19/08/27 09:32:52 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:32:52 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 1836.1602605346454 msec.
19/08/27 09:32:54 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024
19/08/27 09:32:54 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:32:54 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 4150.525246017721 msec.
19/08/27 09:32:54 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001
19/08/27 09:32:54 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:32:54 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 6657.816283545213 msec.
19/08/27 09:32:58 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024
19/08/27 09:32:58 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:32:58 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 7228.437735294442 msec.
19/08/27 09:33:01 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001
19/08/27 09:33:01 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:01 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 8317.245815204433 msec.
19/08/27 09:33:05 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:05 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:05 WARN hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:05 ERROR executor.Executor: Exception in task 939.0 in stage 0.0 (TID 97)
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742618_1794 file=/user/nnnnnven1000G/HSsort-input/part-r-00024
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:05 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 413
19/08/27 09:33:05 INFO executor.Executor: Running task 16.1 in stage 0.0 (TID 413)
19/08/27 09:33:05 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:17179869184+1073741824
19/08/27 09:33:05 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
19/08/27 09:33:05 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:05 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 2820.5052179615636 msec.
19/08/27 09:33:08 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
19/08/27 09:33:08 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:08 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 7636.941779369232 msec.
19/08/27 09:33:09 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:09 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:09 WARN hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:09 ERROR executor.Executor: Exception in task 40.0 in stage 0.0 (TID 16)
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073741894_1070 file=/user/nnnnnven1000G/HSsort-input/part-r-00001
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 444
19/08/27 09:33:09 INFO executor.Executor: Running task 127.1 in stage 0.0 (TID 444)
19/08/27 09:33:09 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00003:13958643712+1073741824
19/08/27 09:33:09 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003
19/08/27 09:33:09 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:09 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 1847.4137662286685 msec.
19/08/27 09:33:11 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003
19/08/27 09:33:11 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:11 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 3467.4737653058146 msec.
19/08/27 09:33:14 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003
19/08/27 09:33:14 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:14 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 12106.024176531228 msec.
19/08/27 09:33:16 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
19/08/27 09:33:16 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:16 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 8169.126280948318 msec.
19/08/27 09:33:24 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:24 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:24 WARN hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:24 ERROR executor.Executor: Exception in task 16.1 in stage 0.0 (TID 413)
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742313_1489 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 552
19/08/27 09:33:24 INFO executor.Executor: Running task 296.2 in stage 0.0 (TID 552)
19/08/27 09:33:24 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00007:32212254720+1073741824
19/08/27 09:33:24 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 file=/user/nnnnnven1000G/HSsort-input/part-r-00007
19/08/27 09:33:24 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:24 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 1965.4591924701708 msec.
19/08/27 09:33:26 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 file=/user/nnnnnven1000G/HSsort-input/part-r-00007
19/08/27 09:33:26 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:26 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 4545.701983924815 msec.
19/08/27 09:33:26 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:26 WARN hdfs.DFSClient: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003 No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException
19/08/27 09:33:26 WARN hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:26 ERROR executor.Executor: Exception in task 127.1 in stage 0.0 (TID 444)
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1096908835-10.1.1.4-1566790228469:blk_1073742233_1409 file=/user/nnnnnven1000G/HSsort-input/part-r-00003
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:946)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:604)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:844)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:896)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at com.github.ehiggs.spark.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.scala:75)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:230)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
19/08/27 09:33:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 590
19/08/27 09:33:26 INFO executor.Executor: Running task 6.2 in stage 0.0 (TID 590)
19/08/27 09:33:27 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:6442450944+1073741824
19/08/27 09:33:27 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742017_1193 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
19/08/27 09:33:27 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742017_1193 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742017_1193 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:27 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 2513.3297360230736 msec.
19/08/27 09:33:29 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742017_1193 file=/user/nnnnnven1000G/HSsort-input/part-r-00000
19/08/27 09:33:29 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742017_1193 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742017_1193 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:29 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 8473.45088137907 msec.
19/08/27 09:33:30 INFO hdfs.DFSClient: No node available for BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 file=/user/nnnnnven1000G/HSsort-input/part-r-00007
19/08/27 09:33:30 INFO hdfs.DFSClient: Could not obtain BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 from any node: java.io.IOException: No live nodes contain block BP-1096908835-10.1.1.4-1566790228469:blk_1073742706_1882 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...
19/08/27 09:33:30 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 6095.756495239792 msec.
19/08/27 09:33:35 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/08/27 09:33:35 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
