Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker0/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker0/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=44189" "-Dspark.network.timeout=40000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:44189" "--executor-id" "61" "--hostname" "10.1.1.4" "--cores" "4" "--app-id" "app-20190827213819-0021" "--worker-url" "spark://Worker@10.1.1.4:46217"
========================================

19/08/27 21:38:19 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 110230@mdc-ch1-cust4
19/08/27 21:38:19 INFO util.SignalUtils: Registered signal handler for TERM
19/08/27 21:38:19 INFO util.SignalUtils: Registered signal handler for HUP
19/08/27 21:38:19 INFO util.SignalUtils: Registered signal handler for INT
19/08/27 21:38:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/27 21:38:19 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/08/27 21:38:19 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/08/27 21:38:19 INFO spark.SecurityManager: Changing view acls groups to: 
19/08/27 21:38:19 INFO spark.SecurityManager: Changing modify acls groups to: 
19/08/27 21:38:19 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/08/27 21:38:20 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:44189 after 79 ms (0 ms spent in bootstraps)
19/08/27 21:38:20 WARN spark.SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/08/27 21:38:20 WARN spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
19/08/27 21:38:20 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/08/27 21:38:20 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/08/27 21:38:20 INFO spark.SecurityManager: Changing view acls groups to: 
19/08/27 21:38:20 INFO spark.SecurityManager: Changing modify acls groups to: 
19/08/27 21:38:20 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/08/27 21:38:20 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:44189 after 2 ms (0 ms spent in bootstraps)
19/08/27 21:38:20 INFO storage.DiskBlockManager: Created local directory at /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-02b0afcb-3a02-41d3-8919-c456602fdd9e/blockmgr-4fafb646-318a-436f-8679-13b21a28400c
19/08/27 21:38:20 INFO memory.MemoryStore: MemoryStore started with capacity 4.1 GB
19/08/27 21:38:20 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:44189
19/08/27 21:38:20 INFO worker.WorkerWatcher: Connecting to worker spark://Worker@10.1.1.4:46217
19/08/27 21:38:20 INFO client.TransportClientFactory: Successfully created connection to /10.1.1.4:46217 after 2 ms (0 ms spent in bootstraps)
19/08/27 21:38:20 INFO worker.WorkerWatcher: Successfully connected to spark://Worker@10.1.1.4:46217
19/08/27 21:38:20 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
19/08/27 21:38:20 INFO executor.Executor: Starting executor ID 61 on host 10.1.1.4
19/08/27 21:38:21 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43497.
19/08/27 21:38:21 INFO netty.NettyBlockTransferService: Server created on 10.1.1.4:43497
19/08/27 21:38:21 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/27 21:38:21 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(61, 10.1.1.4, 43497, None)
19/08/27 21:38:21 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(61, 10.1.1.4, 43497, None)
19/08/27 21:38:21 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(61, 10.1.1.4, 43497, None)
19/08/27 21:38:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 340
19/08/27 21:38:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 341
19/08/27 21:38:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 342
19/08/27 21:38:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 343
19/08/27 21:38:21 INFO executor.Executor: Running task 343.0 in stage 0.0 (TID 343)
19/08/27 21:38:21 INFO executor.Executor: Running task 342.0 in stage 0.0 (TID 342)
19/08/27 21:38:21 INFO executor.Executor: Running task 341.0 in stage 0.0 (TID 341)
19/08/27 21:38:21 INFO executor.Executor: Running task 340.0 in stage 0.0 (TID 340)
19/08/27 21:38:21 INFO executor.Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:44189/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1566967098897
19/08/27 21:38:21 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:44189 after 2 ms (0 ms spent in bootstraps)
19/08/27 21:38:21 INFO util.Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:44189/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-02b0afcb-3a02-41d3-8919-c456602fdd9e/spark-3b1fc1b9-4f25-40d7-8498-ac246b98a02e/fetchFileTemp7184495095457823477.tmp
19/08/27 21:38:21 INFO util.Utils: Copying /data/spark-6e9264d8-6fb2-4eff-a979-6d4b27dc7a35/executor-02b0afcb-3a02-41d3-8919-c456602fdd9e/spark-3b1fc1b9-4f25-40d7-8498-ac246b98a02e/-13844402511566967098897_cache to /var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190827213819-0021/61/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/08/27 21:38:21 INFO executor.Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker0/work/app-20190827213819-0021/61/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/08/27 21:38:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
19/08/27 21:38:21 INFO client.TransportClientFactory: Successfully created connection to /10.1.1.4:32873 after 1 ms (0 ms spent in bootstraps)
19/08/27 21:38:21 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/08/27 21:38:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 135 ms
19/08/27 21:38:21 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/08/27 21:38:21 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00009:0+1073741824
19/08/27 21:38:21 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00008:39728447488+271552512
19/08/27 21:38:21 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00008:38654705664+1073741824
19/08/27 21:38:21 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00009:1073741824+1073741824
19/08/27 21:38:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
19/08/27 21:38:21 INFO client.TransportClientFactory: Successfully created connection to /10.1.1.4:43463 after 1 ms (0 ms spent in bootstraps)
19/08/27 21:38:21 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/08/27 21:38:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 33 ms
19/08/27 21:38:22 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/08/27 21:40:00 INFO executor.Executor: Finished task 341.0 in stage 0.0 (TID 341). 1937 bytes result sent to driver
19/08/27 21:40:00 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 515
19/08/27 21:40:00 INFO executor.Executor: Running task 475.0 in stage 0.0 (TID 515)
19/08/27 21:40:00 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00012:20401094656+1073741824
19/08/27 21:41:39 INFO executor.Executor: Executor is trying to kill task 342.0 in stage 0.0 (TID 342), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor is trying to kill task 475.0 in stage 0.0 (TID 515), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor is trying to kill task 340.0 in stage 0.0 (TID 340), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor is trying to kill task 343.0 in stage 0.0 (TID 343), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor killed task 475.0 in stage 0.0 (TID 515), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor killed task 342.0 in stage 0.0 (TID 342), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor killed task 343.0 in stage 0.0 (TID 343), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.Executor: Executor killed task 340.0 in stage 0.0 (TID 340), reason: Stage cancelled
19/08/27 21:41:39 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/08/27 21:41:39 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
