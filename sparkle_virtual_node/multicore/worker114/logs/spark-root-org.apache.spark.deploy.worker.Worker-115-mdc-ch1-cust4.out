OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
Spark Command: /usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java -cp /var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8309 spark://mdc-ch1-cust4:7077 -h mdc-ch1-cust4
========================================
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/13 04:17:21 INFO Worker: Started daemon with process name: 774930@mdc-ch1-cust4
19/06/13 04:17:21 INFO SignalUtils: Registered signal handler for TERM
19/06/13 04:17:21 INFO SignalUtils: Registered signal handler for HUP
19/06/13 04:17:21 INFO SignalUtils: Registered signal handler for INT
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
19/06/13 04:17:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/13 04:17:21 INFO SecurityManager: Changing view acls to: root
19/06/13 04:17:21 INFO SecurityManager: Changing modify acls to: root
19/06/13 04:17:21 INFO SecurityManager: Changing view acls groups to: 
19/06/13 04:17:21 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 04:17:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
19/06/13 04:17:22 INFO Utils: Successfully started service 'sparkWorker' on port 41563.
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
19/06/13 04:17:22 INFO Worker: Starting Spark worker mdc-ch1-cust4:41563 with 1152 cores, 22.9 TB RAM
19/06/13 04:17:22 INFO Worker: Running Spark version 2.4.0
19/06/13 04:17:22 INFO Worker: Spark home: /var/tmp/spark2.0hpcplatform/multicore/worker114
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
OpenJDK 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (1152) which may exceed available processors
19/06/13 04:17:22 INFO Utils: Successfully started service 'WorkerUI' on port 8309.
19/06/13 04:17:22 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://mdc-ch1-cust4.mdc.ext.hpe.com:8309
19/06/13 04:17:22 INFO Worker: Connecting to master mdc-ch1-cust4:7077...
19/06/13 04:17:22 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:7077 after 19 ms (0 ms spent in bootstraps)
19/06/13 04:17:22 INFO Worker: Successfully registered with master spark://mdc-ch1-cust4.mdc.ext.hpe.com:7077
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13248 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13249 for TeraSort
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13250 for TeraSort
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13251 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13248" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13252 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13253 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13254 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13255 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13256 for TeraSort
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13257 for TeraSort
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13258 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13259 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13260 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13261 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13262 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13250" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13263 for TeraSort
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13264 for TeraSort
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13251" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13265 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13266 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13267 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13268 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13269 for TeraSort
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13270 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13271 for TeraSort
19/06/13 07:42:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13253" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13272 for TeraSort
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13249" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13256" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13265" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13258" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13255" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13266" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13260" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13252" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13254" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13257" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13271" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13263" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13270" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13269" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13267" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13259" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13261" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13268" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:33 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13264" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:33 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:33 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13262" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:33 INFO Worker: Asked to launch executor app-20190613074230-0000/13273 for TeraSort
19/06/13 07:42:35 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:35 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:35 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:35 INFO Worker: Asked to launch executor app-20190613074230-0000/13274 for TeraSort
19/06/13 07:42:35 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:35 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:35 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:35 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:35 INFO Worker: Asked to launch executor app-20190613074230-0000/13275 for TeraSort
19/06/13 07:42:35 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13272" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:36 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13273" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:36 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:36 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:36 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:36 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:36 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:36 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:36 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:36 INFO Worker: Asked to launch executor app-20190613074230-0000/13276 for TeraSort
19/06/13 07:42:36 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:36 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13275" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:36 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13274" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13276" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13277 for TeraSort
19/06/13 07:42:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13278 for TeraSort
19/06/13 07:42:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13279 for TeraSort
19/06/13 07:42:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13277" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13278" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13280 for TeraSort
19/06/13 07:42:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:38 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:38 INFO Worker: Asked to launch executor app-20190613074230-0000/13281 for TeraSort
19/06/13 07:42:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13279" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13280" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:42 INFO Worker: Asked to launch executor app-20190613074230-0000/13282 for TeraSort
19/06/13 07:42:42 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:42 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:42 INFO Worker: Asked to launch executor app-20190613074230-0000/13283 for TeraSort
19/06/13 07:42:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13284 for TeraSort
19/06/13 07:42:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:42:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:42:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:42:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:42:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:48 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13282" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:48 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13281" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:42:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13285 for TeraSort
19/06/13 07:42:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:01 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:01 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:01 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:01 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:01 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:01 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:01 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:42:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13286 for TeraSort
19/06/13 07:43:01 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13283" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:01 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13285" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:02 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13284" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:02 WARN NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@46d02083.
19/06/13 07:43:02 INFO NioEventLoop: Migrated 0 channel(s) to the new Selector.
19/06/13 07:43:02 WARN NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@770ced51.
19/06/13 07:43:04 INFO NioEventLoop: Migrated 0 channel(s) to the new Selector.
19/06/13 07:43:04 ERROR TransportRequestHandler: Error sending result RpcResponse{requestId=6356357673564978715, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=47 cap=64]}} to /10.1.1.4:52610; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
19/06/13 07:43:03 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:04 ERROR TransportRequestHandler: Error sending result RpcResponse{requestId=8498351630459780392, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=47 cap=64]}} to /10.1.1.4:53010; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
19/06/13 07:43:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13287 for TeraSort
19/06/13 07:43:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13286" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:05 INFO Worker: Asked to launch executor app-20190613074230-0000/13288 for TeraSort
19/06/13 07:43:05 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:05 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:05 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:05 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:05 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13287" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:05 INFO Worker: Asked to launch executor app-20190613074230-0000/13289 for TeraSort
19/06/13 07:43:05 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:06 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:06 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:06 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:06 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13288" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:07 INFO Worker: Asked to launch executor app-20190613074230-0000/13290 for TeraSort
19/06/13 07:43:07 INFO Worker: Asked to launch executor app-20190613074230-0000/13291 for TeraSort
19/06/13 07:43:07 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:08 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13290" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13289" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13292 for TeraSort
19/06/13 07:43:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13293 for TeraSort
19/06/13 07:43:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:10 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13292" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13294 for TeraSort
19/06/13 07:43:10 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13291" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13295 for TeraSort
19/06/13 07:43:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:11 INFO Worker: Asked to launch executor app-20190613074230-0000/13296 for TeraSort
19/06/13 07:43:11 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:30 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:30 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:30 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:30 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:30 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:30 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:30 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:30 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:30 INFO Worker: Asked to launch executor app-20190613074230-0000/13297 for TeraSort
19/06/13 07:43:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13293" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13295" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13296" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:34 INFO Worker: Asked to launch executor app-20190613074230-0000/13298 for TeraSort
19/06/13 07:43:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13294" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:34 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:35 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:35 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:35 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:36 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13297" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:36 INFO Worker: Asked to launch executor app-20190613074230-0000/13299 for TeraSort
19/06/13 07:43:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13300 for TeraSort
19/06/13 07:43:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13301 for TeraSort
19/06/13 07:43:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13302 for TeraSort
19/06/13 07:43:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:37 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13300" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13298" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13301" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:37 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13299" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:37 INFO Worker: Asked to launch executor app-20190613074230-0000/13303 for TeraSort
19/06/13 07:43:37 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:39 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:39 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:39 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:39 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13302" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:38 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:39 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:39 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:39 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:38 INFO Worker: Asked to launch executor app-20190613074230-0000/13304 for TeraSort
19/06/13 07:43:39 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13303" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:39 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:39 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:39 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:39 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:39 INFO Worker: Asked to launch executor app-20190613074230-0000/13305 for TeraSort
19/06/13 07:43:39 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13304" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13306 for TeraSort
19/06/13 07:43:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13307 for TeraSort
19/06/13 07:43:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13305" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13308 for TeraSort
19/06/13 07:43:42 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:42 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:42 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:42 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:43 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13306" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:43 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13307" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:43 INFO Worker: Asked to launch executor app-20190613074230-0000/13309 for TeraSort
19/06/13 07:43:43 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13310 for TeraSort
19/06/13 07:43:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13311 for TeraSort
19/06/13 07:43:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13312 for TeraSort
19/06/13 07:43:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13313 for TeraSort
19/06/13 07:43:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13314 for TeraSort
19/06/13 07:43:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13315 for TeraSort
19/06/13 07:43:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13308" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13311" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13316 for TeraSort
19/06/13 07:43:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13317 for TeraSort
19/06/13 07:43:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13318 for TeraSort
19/06/13 07:43:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13319 for TeraSort
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13309" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13313" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13310" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13314" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13312" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13317" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13320 for TeraSort
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13315" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13318" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13316" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13319" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:48 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13320" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13321 for TeraSort
19/06/13 07:43:49 INFO Worker: Asked to launch executor app-20190613074230-0000/13322 for TeraSort
19/06/13 07:43:49 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:49 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:49 INFO Worker: Asked to launch executor app-20190613074230-0000/13323 for TeraSort
19/06/13 07:43:49 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:49 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:49 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:49 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:49 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:49 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:49 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13321" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:49 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13322" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:49 INFO Worker: Asked to launch executor app-20190613074230-0000/13324 for TeraSort
19/06/13 07:43:49 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13323" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13325 for TeraSort
19/06/13 07:43:50 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13324" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13326 for TeraSort
19/06/13 07:43:50 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13325" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13327 for TeraSort
19/06/13 07:43:50 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:50 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13328 for TeraSort
19/06/13 07:43:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13326" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13327" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13329 for TeraSort
19/06/13 07:43:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13328" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13330 for TeraSort
19/06/13 07:43:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13331 for TeraSort
19/06/13 07:43:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13332 for TeraSort
19/06/13 07:43:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13329" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13330" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13331" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13333 for TeraSort
19/06/13 07:43:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13334 for TeraSort
19/06/13 07:43:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13335 for TeraSort
19/06/13 07:43:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13333" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13332" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13334" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13336 for TeraSort
19/06/13 07:43:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:43:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13335" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:43:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13337 for TeraSort
19/06/13 07:43:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13338 for TeraSort
19/06/13 07:43:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:43:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:43:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13337" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:13 INFO Worker: Asked to launch executor app-20190613074230-0000/13339 for TeraSort
19/06/13 07:44:13 INFO Worker: Asked to launch executor app-20190613074230-0000/13340 for TeraSort
19/06/13 07:44:13 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:13 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:13 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:13 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:13 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:13 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:13 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:13 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:13 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:15 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:15 INFO Worker: Asked to launch executor app-20190613074230-0000/13341 for TeraSort
19/06/13 07:44:15 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13339" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:15 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13338" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:15 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13336" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:15 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13340" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:15 INFO Worker: Asked to launch executor app-20190613074230-0000/13342 for TeraSort
19/06/13 07:44:15 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:15 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13341" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:15 INFO Worker: Asked to launch executor app-20190613074230-0000/13343 for TeraSort
19/06/13 07:44:15 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:15 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:15 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13342" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:16 INFO Worker: Asked to launch executor app-20190613074230-0000/13344 for TeraSort
19/06/13 07:44:16 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:16 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:16 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:16 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:16 INFO Worker: Asked to launch executor app-20190613074230-0000/13345 for TeraSort
19/06/13 07:44:16 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:16 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:16 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:16 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:16 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13343" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:16 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13344" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:17 INFO Worker: Asked to launch executor app-20190613074230-0000/13346 for TeraSort
19/06/13 07:44:17 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:17 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:17 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:17 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:17 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13345" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:19 INFO Worker: Asked to launch executor app-20190613074230-0000/13347 for TeraSort
19/06/13 07:44:19 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:19 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13346" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:19 INFO Worker: Asked to launch executor app-20190613074230-0000/13348 for TeraSort
19/06/13 07:44:19 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:19 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13347" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:19 INFO Worker: Asked to launch executor app-20190613074230-0000/13349 for TeraSort
19/06/13 07:44:19 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:19 INFO Worker: Asked to launch executor app-20190613074230-0000/13350 for TeraSort
19/06/13 07:44:19 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:19 INFO Worker: Asked to launch executor app-20190613074230-0000/13351 for TeraSort
19/06/13 07:44:19 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:19 INFO Worker: Asked to launch executor app-20190613074230-0000/13352 for TeraSort
19/06/13 07:44:19 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:19 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:19 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13348" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:19 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13349" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:19 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13351" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:19 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13350" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:21 INFO Worker: Asked to launch executor app-20190613074230-0000/13353 for TeraSort
19/06/13 07:44:21 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:21 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:21 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:21 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:21 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13352" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:21 INFO Worker: Asked to launch executor app-20190613074230-0000/13354 for TeraSort
19/06/13 07:44:21 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:21 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:21 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:21 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:21 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13353" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:21 INFO Worker: Asked to launch executor app-20190613074230-0000/13355 for TeraSort
19/06/13 07:44:21 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:21 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:21 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:21 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:21 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13354" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:23 INFO Worker: Asked to launch executor app-20190613074230-0000/13356 for TeraSort
19/06/13 07:44:23 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:23 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:23 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:23 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:23 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13355" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:25 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:25 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:25 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:25 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:25 INFO Worker: Asked to launch executor app-20190613074230-0000/13357 for TeraSort
19/06/13 07:44:25 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13356" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:26 INFO Worker: Asked to launch executor app-20190613074230-0000/13358 for TeraSort
19/06/13 07:44:26 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:26 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:26 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:26 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:26 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13357" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:28 INFO Worker: Asked to launch executor app-20190613074230-0000/13359 for TeraSort
19/06/13 07:44:28 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:28 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13358" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:28 INFO Worker: Asked to launch executor app-20190613074230-0000/13360 for TeraSort
19/06/13 07:44:28 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:28 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13359" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:28 INFO Worker: Asked to launch executor app-20190613074230-0000/13361 for TeraSort
19/06/13 07:44:28 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:28 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13360" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:28 INFO Worker: Asked to launch executor app-20190613074230-0000/13362 for TeraSort
19/06/13 07:44:28 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:28 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:29 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13361" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:29 INFO Worker: Asked to launch executor app-20190613074230-0000/13363 for TeraSort
19/06/13 07:44:29 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:29 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:29 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:29 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:29 INFO Worker: Asked to launch executor app-20190613074230-0000/13364 for TeraSort
19/06/13 07:44:29 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:29 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:29 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:29 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:29 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13362" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:29 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13363" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:29 INFO Worker: Asked to launch executor app-20190613074230-0000/13365 for TeraSort
19/06/13 07:44:29 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:29 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:29 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:29 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:29 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13364" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:30 INFO Worker: Asked to launch executor app-20190613074230-0000/13366 for TeraSort
19/06/13 07:44:30 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:30 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:30 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:30 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:30 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13365" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:31 INFO Worker: Asked to launch executor app-20190613074230-0000/13367 for TeraSort
19/06/13 07:44:31 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:31 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:31 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:31 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13366" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:31 INFO Worker: Asked to launch executor app-20190613074230-0000/13368 for TeraSort
19/06/13 07:44:31 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:31 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:31 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:31 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13367" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:31 INFO Worker: Asked to launch executor app-20190613074230-0000/13369 for TeraSort
19/06/13 07:44:31 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:31 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:31 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:31 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:31 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13368" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13370 for TeraSort
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13371 for TeraSort
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13372 for TeraSort
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13373 for TeraSort
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13369" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13374 for TeraSort
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13371" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13370" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13372" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13373" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13375 for TeraSort
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13374" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:32 INFO Worker: Asked to launch executor app-20190613074230-0000/13376 for TeraSort
19/06/13 07:44:32 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:32 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:32 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13375" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:33 INFO Worker: Asked to launch executor app-20190613074230-0000/13377 for TeraSort
19/06/13 07:44:33 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:33 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:33 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:33 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:33 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13376" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:33 INFO Worker: Asked to launch executor app-20190613074230-0000/13378 for TeraSort
19/06/13 07:44:33 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:33 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:33 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:33 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13377" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:34 INFO Worker: Asked to launch executor app-20190613074230-0000/13379 for TeraSort
19/06/13 07:44:34 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:34 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:34 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:34 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:34 INFO Worker: Asked to launch executor app-20190613074230-0000/13380 for TeraSort
19/06/13 07:44:34 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:34 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:34 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:34 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13378" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:34 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13379" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:34 INFO Worker: Asked to launch executor app-20190613074230-0000/13381 for TeraSort
19/06/13 07:44:34 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:34 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:34 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:34 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:39 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13380" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:39 INFO Worker: Asked to launch executor app-20190613074230-0000/13382 for TeraSort
19/06/13 07:44:39 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:39 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:39 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:39 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13381" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13383 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13382" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13384 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13385 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13383" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13384" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13386 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13387 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13386" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13388 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13385" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13389 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13387" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO Worker: Asked to launch executor app-20190613074230-0000/13390 for TeraSort
19/06/13 07:44:40 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:40 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13388" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:40 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13389" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:41 INFO Worker: Asked to launch executor app-20190613074230-0000/13391 for TeraSort
19/06/13 07:44:41 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:41 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:41 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:41 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:41 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13390" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:41 INFO Worker: Asked to launch executor app-20190613074230-0000/13392 for TeraSort
19/06/13 07:44:41 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:41 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:41 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:41 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:41 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13391" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:42 INFO Worker: Asked to launch executor app-20190613074230-0000/13393 for TeraSort
19/06/13 07:44:42 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:42 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:42 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:42 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:42 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13392" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:43 INFO Worker: Asked to launch executor app-20190613074230-0000/13394 for TeraSort
19/06/13 07:44:43 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:43 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:43 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:43 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:43 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13393" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13395 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13394" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13396 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13395" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13397 for TeraSort
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13398 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13397" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13396" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13399 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13398" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13400 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13401 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13400" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13402 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13399" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13403 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO Worker: Asked to launch executor app-20190613074230-0000/13404 for TeraSort
19/06/13 07:44:44 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:44 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:44 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13402" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13401" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13405 for TeraSort
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13403" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13406 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13407 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13405" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13404" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13406" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13408 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13407" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13409 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13408" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13410 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13409" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13411 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13410" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:45 INFO Worker: Asked to launch executor app-20190613074230-0000/13412 for TeraSort
19/06/13 07:44:45 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:45 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:45 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13411" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:46 INFO Worker: Asked to launch executor app-20190613074230-0000/13413 for TeraSort
19/06/13 07:44:46 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:46 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:46 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:46 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:46 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13412" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:46 INFO Worker: Asked to launch executor app-20190613074230-0000/13414 for TeraSort
19/06/13 07:44:46 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:46 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:46 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:46 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:46 INFO Worker: Asked to launch executor app-20190613074230-0000/13415 for TeraSort
19/06/13 07:44:46 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:46 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:46 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:46 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13414" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13413" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13416 for TeraSort
19/06/13 07:44:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13415" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13417 for TeraSort
19/06/13 07:44:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13418 for TeraSort
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13416" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13419 for TeraSort
19/06/13 07:44:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13418" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:47 INFO Worker: Asked to launch executor app-20190613074230-0000/13420 for TeraSort
19/06/13 07:44:47 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:47 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13419" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:47 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13417" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13421 for TeraSort
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:48 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13420" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13422 for TeraSort
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13423 for TeraSort
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:48 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13421" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:48 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13422" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13424 for TeraSort
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13425 for TeraSort
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13426 for TeraSort
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:48 INFO Worker: Asked to launch executor app-20190613074230-0000/13427 for TeraSort
19/06/13 07:44:48 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:48 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13428 for TeraSort
19/06/13 07:44:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13429 for TeraSort
19/06/13 07:44:50 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13423" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13424" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13428" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:50 INFO Worker: Asked to launch executor app-20190613074230-0000/13430 for TeraSort
19/06/13 07:44:50 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:50 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:50 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:50 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:50 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13429" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13431 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13432 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13433 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13430" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13434 for TeraSort
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13435 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13432" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13434" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13431" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13436 for TeraSort
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13433" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13437 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13438 for TeraSort
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13439 for TeraSort
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13435" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13440 for TeraSort
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13436" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13437" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13441 for TeraSort
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13438" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13439" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13442 for TeraSort
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13443 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO Worker: Asked to launch executor app-20190613074230-0000/13444 for TeraSort
19/06/13 07:44:51 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:51 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:51 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13440" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13445 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13446 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13441" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13425" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13447 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13442" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13448 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13449 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13450 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13451 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13426" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13444" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13452 for TeraSort
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13453 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13445" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13427" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13443" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13446" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13451" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13447" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13454 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13449" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13455 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13448" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13456 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13450" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13452" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13453" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13454" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13457 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13458 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13455" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13459 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13460 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13461 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13462 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13459" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13457" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13463 for TeraSort
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13458" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13464 for TeraSort
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13456" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13461" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13462" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13463" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13465 for TeraSort
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13460" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13466 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13467 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13468 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13465" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13467" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13464" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13469 for TeraSort
19/06/13 07:44:52 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:52 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:52 INFO Worker: Asked to launch executor app-20190613074230-0000/13470 for TeraSort
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13471 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13472 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13473 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13474 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13475 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13476 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13477 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13478 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13479 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13480 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13481 for TeraSort
19/06/13 07:44:53 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:53 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:54 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:54 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:54 INFO Worker: Asked to launch executor app-20190613074230-0000/13482 for TeraSort
19/06/13 07:44:54 INFO Worker: Asked to launch executor app-20190613074230-0000/13483 for TeraSort
19/06/13 07:44:54 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13468" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:54 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:54 INFO Worker: Asked to launch executor app-20190613074230-0000/13484 for TeraSort
19/06/13 07:44:54 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:54 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13466" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:54 INFO Worker: Asked to launch executor app-20190613074230-0000/13485 for TeraSort
19/06/13 07:44:54 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:54 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13486 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13487 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13488 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13489 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13490 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13491 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13485" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13487" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13484" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13470" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13474" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13480" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13472" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13475" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13482" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13471" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13478" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13476" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13479" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13481" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13469" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13488" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13483" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13492 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13486" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13493 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13494 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13495 for TeraSort
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13473" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13477" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13489" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13496 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13490" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13491" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13493" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13492" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13494" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13497 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13495" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13498 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13499 for TeraSort
19/06/13 07:44:55 INFO SecurityManager: Changing view acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:44:55 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:44:55 INFO Worker: Asked to launch executor app-20190613074230-0000/13500 for TeraSort
19/06/13 07:45:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13418,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13496" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:03 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13498" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:03 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:03 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13497" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:01 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13422,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13417,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13501 for TeraSort
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13499" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13500" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13502 for TeraSort
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 INFO ExecutorRunner: Killing process!
19/06/13 07:45:04 INFO ExecutorRunner: Killing process!
19/06/13 07:45:04 INFO ExecutorRunner: Killing process!
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13503 for TeraSort
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13501" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13503 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13504 for TeraSort
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13504 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 INFO Worker: Executor app-20190613074230-0000/13253 finished with state EXITED message Command exited with code 1 exitStatus 1
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13503" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 13253
19/06/13 07:45:04 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190613074230-0000, execId=13253)
19/06/13 07:45:04 INFO Worker: Executor app-20190613074230-0000/13250 finished with state EXITED message Command exited with code 1 exitStatus 1
19/06/13 07:45:04 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 13250
19/06/13 07:45:04 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190613074230-0000, execId=13250)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13505 for TeraSort
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13502" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13504" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13505 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13506 for TeraSort
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13506 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13507 for TeraSort
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13505" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13507 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13508 for TeraSort
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13508 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13509 for TeraSort
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13506" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 ERROR Worker: Failed to launch executor app-20190613074230-0000/13509 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:04 INFO Worker: Asked to launch executor app-20190613074230-0000/13510 for TeraSort
19/06/13 07:45:04 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:04 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13508" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:04 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13507" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:05 ERROR Worker: Failed to launch executor app-20190613074230-0000/13510 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:05 INFO Worker: Asked to launch executor app-20190613074230-0000/13511 for TeraSort
19/06/13 07:45:05 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:05 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:05 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:05 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:05 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13510" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:05 ERROR Worker: Failed to launch executor app-20190613074230-0000/13511 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:05 INFO Worker: Asked to launch executor app-20190613074230-0000/13512 for TeraSort
19/06/13 07:45:05 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:05 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:05 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:05 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:05 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13509" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:05 ERROR Worker: Failed to launch executor app-20190613074230-0000/13512 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:05 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:05 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:05 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:05 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:05 INFO Worker: Asked to launch executor app-20190613074230-0000/13513 for TeraSort
19/06/13 07:45:05 ERROR Worker: Failed to launch executor app-20190613074230-0000/13513 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:08 INFO Worker: Asked to launch executor app-20190613074230-0000/13514 for TeraSort
19/06/13 07:45:07 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:07 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13512" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:07 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13511" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:08 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13513" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:08 ERROR Worker: Failed to launch executor app-20190613074230-0000/13514 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:08 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:08 INFO Worker: Asked to launch executor app-20190613074230-0000/13515 for TeraSort
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:08 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13514" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:08 ERROR Worker: Failed to launch executor app-20190613074230-0000/13515 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:08 INFO Worker: Asked to launch executor app-20190613074230-0000/13516 for TeraSort
19/06/13 07:45:08 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:08 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13515" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:08 ERROR Worker: Failed to launch executor app-20190613074230-0000/13516 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:08 INFO Worker: Asked to launch executor app-20190613074230-0000/13517 for TeraSort
19/06/13 07:45:08 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:08 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:08 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13516" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13517 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13518 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13517" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13518 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13519 for TeraSort
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13519 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13520 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13520 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13521 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13518" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13521 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13522 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13520" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13519" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13522 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13523 for TeraSort
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13523 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13524 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13521" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13524 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13525 for TeraSort
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13525 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13526 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13522" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13526 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13527 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13525" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13523" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13527 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13528 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13524" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13528 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13529 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13526" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13529 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13530 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13527" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13530 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13531 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13528" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13531 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13532 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13531" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13530" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13532 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13533 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13533 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13534 for TeraSort
19/06/13 07:45:09 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13529" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:09 ERROR Worker: Failed to launch executor app-20190613074230-0000/13534 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:09 INFO Worker: Asked to launch executor app-20190613074230-0000/13535 for TeraSort
19/06/13 07:45:09 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:09 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13532" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13535 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13534" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13536 for TeraSort
19/06/13 07:45:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13536 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13537 for TeraSort
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13537 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13538 for TeraSort
19/06/13 07:45:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13538 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13539 for TeraSort
19/06/13 07:45:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13539 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13540 for TeraSort
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13540 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13541 for TeraSort
19/06/13 07:45:10 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:10 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:10 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13533" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:10 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13536" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13541 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13542 for TeraSort
19/06/13 07:45:10 ERROR Worker: Failed to launch executor app-20190613074230-0000/13542 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:10 INFO Worker: Asked to launch executor app-20190613074230-0000/13543 for TeraSort
19/06/13 07:45:11 ERROR Worker: Failed to launch executor app-20190613074230-0000/13543 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:11 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:11 INFO Worker: Asked to launch executor app-20190613074230-0000/13544 for TeraSort
19/06/13 07:45:11 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:11 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:11 ERROR Worker: Failed to launch executor app-20190613074230-0000/13544 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:11 INFO Worker: Asked to launch executor app-20190613074230-0000/13545 for TeraSort
19/06/13 07:45:11 ERROR Worker: Failed to launch executor app-20190613074230-0000/13545 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:11 INFO Worker: Asked to launch executor app-20190613074230-0000/13546 for TeraSort
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13542" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13535" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13540" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13541" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13537" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13539" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:11 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13545" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13538" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13543" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:11 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13544" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13546 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13547 for TeraSort
19/06/13 07:45:12 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13546" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13547 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13548 for TeraSort
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13548 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13549 for TeraSort
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13549 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13550 for TeraSort
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13550 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13551 for TeraSort
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13551 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13552 for TeraSort
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13552 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13553 for TeraSort
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13553 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13554 for TeraSort
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13554 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13555 for TeraSort
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13555 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13556 for TeraSort
19/06/13 07:45:12 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13549" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13547" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13550" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:12 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13551" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13553" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:12 ERROR Worker: Failed to launch executor app-20190613074230-0000/13556 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:12 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:12 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:12 INFO Worker: Asked to launch executor app-20190613074230-0000/13557 for TeraSort
19/06/13 07:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:15 ERROR Worker: Failed to launch executor app-20190613074230-0000/13557 for TeraSort.
java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:142)
	at org.apache.spark.deploy.worker.ExecutorRunner.start(ExecutorRunner.scala:77)
	at org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Worker.scala:542)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:45:38 INFO SecurityManager: Changing view acls to: root
19/06/13 07:45:38 INFO SecurityManager: Changing modify acls to: root
19/06/13 07:45:38 INFO SecurityManager: Changing view acls groups to: 
19/06/13 07:45:38 INFO SecurityManager: Changing modify acls groups to: 
19/06/13 07:45:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13426,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13424,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13423,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13428,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13429,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13430,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13432,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13434,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13431,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13433,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13435,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13438,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13436,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13439,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13425,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13441,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13442,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13444,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13445,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13427,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13449,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13448,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13450,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13452,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13453,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13459,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13462,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13463,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13468,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13455,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:15 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13437,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:53 INFO Worker: Asked to launch executor app-20190613074230-0000/13558 for TeraSort
19/06/13 07:45:53 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13556" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:53 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13555" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:53 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13557" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:53 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13554" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:53 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13548" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:53 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13544 interrupted
19/06/13 07:45:53 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13536 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:53 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13524 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:53 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13533 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:53 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13553 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:52 INFO ExecutorRunner: Killing process!
19/06/13 07:45:52 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13547 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13550,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13443,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13446,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13447,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13454,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13457,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13458,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13456,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13461,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13460,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13465,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13467,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13464,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13487,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13480,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13482,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13478,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13476,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13481,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13469,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13488,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13486,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13473,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13477,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13489,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13491,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13493,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:49 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13492,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13512,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13498,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13497,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13500,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13483,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13514,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13494,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13505,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13506,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13508,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13515,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13516,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13517,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13520,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:48 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13521,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:47 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13522,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:47 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13525,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:47 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13523,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:47 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13527,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:45:46 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13530 interrupted
19/06/13 07:45:42 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13541 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:41 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13519 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:39 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13539 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:39 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13540 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:38 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13551 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:38 INFO ExecutorRunner: Launch command: "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker114/conf:/var/tmp/spark2.0hpcplatform/multicore/worker114/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=38039" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:ParallelGCThreads=10" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:38039" "--executor-id" "13552" "--hostname" "mdc-ch1-cust4" "--cores" "2" "--app-id" "app-20190613074230-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:41563"
19/06/13 07:45:38 ERROR ExecutorRunner: Error running executor
java.io.IOException: Cannot run program "/usr/lib64/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java" (in directory "/var/tmp/spark2.0hpcplatform/multicore/worker114/work/app-20190613074230-0000/13549"): error=11, Resource temporarily unavailable
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
Caused by: java.io.IOException: error=11, Resource temporarily unavailable
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 2 more
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:54 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13542 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:54 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13545 interrupted
19/06/13 07:45:54 INFO ExecutorRunner: Killing process!
19/06/13 07:45:55 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13518 interrupted
19/06/13 07:45:55 INFO ExecutorRunner: Killing process!
19/06/13 07:45:55 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13504 interrupted
19/06/13 07:45:55 INFO ExecutorRunner: Killing process!
19/06/13 07:45:57 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13531 interrupted
19/06/13 07:45:57 INFO ExecutorRunner: Killing process!
19/06/13 07:45:58 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13529 interrupted
19/06/13 07:45:58 INFO ExecutorRunner: Killing process!
19/06/13 07:45:58 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13532 interrupted
19/06/13 07:45:58 INFO ExecutorRunner: Killing process!
19/06/13 07:45:59 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13546 interrupted
19/06/13 07:45:59 INFO ExecutorRunner: Killing process!
19/06/13 07:46:00 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13535 interrupted
19/06/13 07:46:00 INFO ExecutorRunner: Killing process!
19/06/13 07:46:00 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13509 interrupted
19/06/13 07:46:00 INFO ExecutorRunner: Killing process!
19/06/13 07:46:00 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13526,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:00 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13513,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:00 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13552,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:00 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13528,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:00 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13556,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:00 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13543,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:01 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13554,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:01 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13555,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:01 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13557,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:01 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[dispatcher-event-loop-852,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1025)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/06/13 07:46:02 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13507,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:177)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:02 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13510,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:02 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13503,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:02 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13511 interrupted
19/06/13 07:46:02 INFO ExecutorRunner: Killing process!
19/06/13 07:46:02 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13537 interrupted
19/06/13 07:46:02 INFO ExecutorRunner: Killing process!
19/06/13 07:46:02 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13538,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.spark.util.logging.FileAppender.<init>(FileAppender.scala:43)
	at org.apache.spark.util.logging.FileAppender$.apply(FileAppender.scala:166)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:02 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[ExecutorRunner for app-20190613074230-0000/13548,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:171)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:73)
19/06/13 07:46:02 INFO ExecutorRunner: Runner thread for executor app-20190613074230-0000/13534 interrupted
19/06/13 07:46:02 INFO ExecutorRunner: Killing process!
19/06/13 07:46:14 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:14 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@36cf9579. This process will likely be orphaned.
19/06/13 07:46:14 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:14 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:14 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@1a005816. This process will likely be orphaned.
19/06/13 07:46:14 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:14 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@532253e8. This process will likely be orphaned.
19/06/13 07:46:14 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@c8306a9. This process will likely be orphaned.
19/06/13 07:46:14 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:14 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@17dfbe66. This process will likely be orphaned.
19/06/13 07:46:14 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:14 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@512a12a2. This process will likely be orphaned.
19/06/13 07:46:15 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:15 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@7e101b9d. This process will likely be orphaned.
19/06/13 07:46:17 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:17 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@3cd65f62. This process will likely be orphaned.
19/06/13 07:46:18 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:18 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@3185f488. This process will likely be orphaned.
19/06/13 07:46:19 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:19 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@4b5daea0. This process will likely be orphaned.
19/06/13 07:46:20 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:20 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@7da041bd. This process will likely be orphaned.
19/06/13 07:46:22 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:22 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@18e67265. This process will likely be orphaned.
19/06/13 07:46:22 INFO ExecutorRunner: Killing process!
19/06/13 07:46:22 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:22 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@11d1f14. This process will likely be orphaned.
19/06/13 07:46:22 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:22 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@319ec01e. This process will likely be orphaned.
19/06/13 07:46:22 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:22 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@74cfa29d. This process will likely be orphaned.
19/06/13 07:46:35 INFO ExecutorRunner: Killing process!
19/06/13 07:46:55 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:46:55 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@4d09b600. This process will likely be orphaned.
19/06/13 07:46:55 INFO ExecutorRunner: Killing process!
19/06/13 07:47:15 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:47:15 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@2ade628a. This process will likely be orphaned.
19/06/13 07:47:15 INFO ExecutorRunner: Killing process!
19/06/13 07:47:35 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:47:35 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@168b3bf8. This process will likely be orphaned.
19/06/13 07:47:35 INFO ExecutorRunner: Killing process!
19/06/13 07:47:55 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:47:55 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@3d551616. This process will likely be orphaned.
19/06/13 07:47:55 INFO ExecutorRunner: Killing process!
19/06/13 07:48:15 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:48:15 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@3d6c0e0a. This process will likely be orphaned.
19/06/13 07:48:15 INFO ExecutorRunner: Killing process!
19/06/13 07:48:35 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:48:35 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@64fff11f. This process will likely be orphaned.
19/06/13 07:48:35 INFO ExecutorRunner: Killing process!
19/06/13 07:48:55 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:48:55 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@2be45283. This process will likely be orphaned.
19/06/13 07:48:55 INFO ExecutorRunner: Killing process!
19/06/13 07:49:15 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:49:15 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@3e14144f. This process will likely be orphaned.
19/06/13 07:49:15 INFO ExecutorRunner: Killing process!
19/06/13 07:49:21 INFO ExecutorRunner: Killing process!
19/06/13 07:49:41 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:49:41 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@635551d9. This process will likely be orphaned.
19/06/13 07:49:41 INFO ExecutorRunner: Killing process!
19/06/13 07:50:01 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:50:01 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@78b923a5. This process will likely be orphaned.
19/06/13 07:50:01 INFO ExecutorRunner: Killing process!
19/06/13 07:50:07 INFO ExecutorRunner: Killing process!
19/06/13 07:50:27 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:50:27 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@71c0067b. This process will likely be orphaned.
19/06/13 07:50:27 INFO ExecutorRunner: Killing process!
19/06/13 07:50:34 INFO ExecutorRunner: Killing process!
19/06/13 07:50:53 INFO ExecutorRunner: Killing process!
19/06/13 07:50:55 INFO ExecutorRunner: Killing process!
19/06/13 07:51:15 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:51:15 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@6fe8c260. This process will likely be orphaned.
19/06/13 07:51:15 INFO ExecutorRunner: Killing process!
19/06/13 07:51:35 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:51:35 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@26fa8ddd. This process will likely be orphaned.
19/06/13 07:51:35 INFO ExecutorRunner: Killing process!
19/06/13 07:51:55 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:51:55 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@176f36ac. This process will likely be orphaned.
19/06/13 07:51:55 INFO ExecutorRunner: Killing process!
19/06/13 07:52:16 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:52:16 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@666d09e4. This process will likely be orphaned.
19/06/13 07:52:16 INFO ExecutorRunner: Killing process!
19/06/13 07:52:36 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:52:36 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@4fbf3c8b. This process will likely be orphaned.
19/06/13 07:52:36 INFO ExecutorRunner: Killing process!
19/06/13 07:52:56 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:52:56 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@3d59c4c4. This process will likely be orphaned.
19/06/13 07:52:56 INFO ExecutorRunner: Killing process!
19/06/13 07:52:56 INFO ExecutorRunner: Killing process!
19/06/13 07:52:57 INFO ExecutorRunner: Killing process!
19/06/13 07:53:01 INFO ExecutorRunner: Killing process!
19/06/13 07:53:01 INFO ExecutorRunner: Killing process!
19/06/13 07:53:11 INFO ExecutorRunner: Killing process!
19/06/13 07:53:11 INFO ExecutorRunner: Killing process!
19/06/13 07:53:11 INFO ExecutorRunner: Killing process!
19/06/13 07:53:31 WARN Utils: Timed out waiting to forcibly kill process
19/06/13 07:53:31 WARN ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@536d4f95. This process will likely be orphaned.
19/06/13 07:53:31 INFO ExecutorRunner: Killing process!
19/06/13 07:53:31 INFO ExecutorRunner: Killing process!
19/06/13 07:53:31 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:53:39 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:01 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ExecutorRunner: Killing process!
19/06/13 07:54:04 INFO ShutdownHookManager: Shutdown hook called
19/06/13 07:54:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d190ffb-f5fb-421f-828c-0c9d4eef9a28
