Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Spark Command: /opt/jdk1.8.0_131/jre/bin/java -cp /var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/ -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8105 spark://mdc-ch1-cust4:7077 -h mdc-ch1-cust4
========================================
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:38:35 INFO worker.Worker: Started daemon with process name: 269058@mdc-ch1-cust4
19/06/19 06:38:35 INFO util.SignalUtils: Registered signal handler for TERM
19/06/19 06:38:35 INFO util.SignalUtils: Registered signal handler for HUP
19/06/19 06:38:35 INFO util.SignalUtils: Registered signal handler for INT
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:38:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/19 06:38:35 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:38:35 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:38:35 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:38:35 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:38:35 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:38:35 INFO util.Utils: Successfully started service 'sparkWorker' on port 42319.
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:38:36 INFO worker.Worker: Starting Spark worker mdc-ch1-cust4:42319 with 576 cores, 22.9 TB RAM
19/06/19 06:38:36 INFO worker.Worker: Running Spark version 2.4.0
19/06/19 06:38:36 INFO worker.Worker: Spark home: /var/tmp/spark2.0hpcplatform/multicore/worker12
19/06/19 06:38:36 INFO util.log: Logging initialized @1572ms
19/06/19 06:38:36 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
19/06/19 06:38:36 INFO server.Server: Started @1619ms
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:38:36 INFO server.AbstractConnector: Started ServerConnector@2570d355{HTTP/1.1,[http/1.1]}{0.0.0.0:8105}
19/06/19 06:38:36 INFO util.Utils: Successfully started service 'WorkerUI' on port 8105.
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e4733c4{/logPage,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@14ed3445{/logPage/json,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@726c2706{/,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3dbeb4b2{/json,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@408ce05c{/static,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c49ec22{/log,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO ui.WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://mdc-ch1-cust4.mdc.ext.hpe.com:8105
19/06/19 06:38:36 INFO worker.Worker: Connecting to master mdc-ch1-cust4:7077...
19/06/19 06:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4159cec3{/metrics/json,null,AVAILABLE,@Spark}
19/06/19 06:38:36 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:7077 after 22 ms (0 ms spent in bootstraps)
19/06/19 06:38:36 INFO worker.Worker: Successfully registered with master spark://mdc-ch1-cust4.mdc.ext.hpe.com:7077
19/06/19 06:45:08 INFO worker.Worker: Asked to launch executor app-20190619064508-0000/33 for TeraSort
19/06/19 06:45:08 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:45:08 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:45:08 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:45:08 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:45:08 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:45:08 INFO worker.Worker: Asked to launch executor app-20190619064508-0000/34 for TeraSort
19/06/19 06:45:08 INFO worker.Worker: Asked to launch executor app-20190619064508-0000/35 for TeraSort
19/06/19 06:45:08 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:45:08 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:45:08 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:45:08 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:45:08 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:45:08 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:45:08 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:45:08 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:45:08 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:45:08 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:45:08 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=36071" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:36071" "--executor-id" "34" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619064508-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 06:45:08 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=36071" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:36071" "--executor-id" "33" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619064508-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 06:45:08 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=36071" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:36071" "--executor-id" "35" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619064508-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 06:54:08 INFO worker.Worker: Asked to kill executor app-20190619064508-0000/34
19/06/19 06:54:08 INFO worker.Worker: Asked to launch executor app-20190619064508-0000/104 for TeraSort
19/06/19 06:54:08 INFO worker.ExecutorRunner: Runner thread for executor app-20190619064508-0000/34 interrupted
19/06/19 06:54:08 INFO worker.ExecutorRunner: Killing process!
19/06/19 06:54:08 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:54:08 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:54:08 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:54:08 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:54:08 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:54:09 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=36071" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:36071" "--executor-id" "104" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619064508-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 06:54:28 WARN util.Utils: Timed out waiting to forcibly kill process
19/06/19 06:54:28 WARN worker.ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@708dc8d2. This process will likely be orphaned.
19/06/19 06:54:28 INFO worker.Worker: Executor app-20190619064508-0000/34 finished with state KILLED
19/06/19 06:54:28 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 34
19/06/19 06:54:28 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619064508-0000, execId=34)
19/06/19 06:54:33 INFO worker.Worker: Asked to kill executor app-20190619064508-0000/104
19/06/19 06:54:33 INFO worker.Worker: Asked to kill executor app-20190619064508-0000/35
19/06/19 06:54:33 INFO worker.Worker: Asked to kill executor app-20190619064508-0000/33
19/06/19 06:54:33 INFO worker.ExecutorRunner: Runner thread for executor app-20190619064508-0000/33 interrupted
19/06/19 06:54:33 INFO worker.ExecutorRunner: Runner thread for executor app-20190619064508-0000/35 interrupted
19/06/19 06:54:33 INFO worker.ExecutorRunner: Killing process!
19/06/19 06:54:33 INFO worker.ExecutorRunner: Runner thread for executor app-20190619064508-0000/104 interrupted
19/06/19 06:54:33 INFO worker.ExecutorRunner: Killing process!
19/06/19 06:54:33 INFO worker.ExecutorRunner: Killing process!
19/06/19 06:54:34 INFO worker.Worker: Executor app-20190619064508-0000/104 finished with state KILLED exitStatus 143
19/06/19 06:54:34 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 104
19/06/19 06:54:34 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619064508-0000, execId=104)
19/06/19 06:54:46 INFO worker.Worker: Executor app-20190619064508-0000/35 finished with state KILLED exitStatus 137
19/06/19 06:54:46 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 35
19/06/19 06:54:46 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619064508-0000, execId=35)
19/06/19 06:54:47 INFO worker.Worker: Executor app-20190619064508-0000/33 finished with state KILLED exitStatus 137
19/06/19 06:54:47 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 33
19/06/19 06:54:47 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619064508-0000, execId=33)
19/06/19 06:54:47 INFO shuffle.ExternalShuffleBlockResolver: Application app-20190619064508-0000 removed, cleanupLocalDirs = true
19/06/19 06:54:47 INFO worker.Worker: Cleaning up local directories for application app-20190619064508-0000
19/06/19 06:57:26 INFO worker.Worker: Asked to launch executor app-20190619065726-0001/33 for TeraSort
19/06/19 06:57:26 INFO worker.Worker: Asked to launch executor app-20190619065726-0001/34 for TeraSort
19/06/19 06:57:26 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:57:26 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:57:26 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:57:26 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:57:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:57:26 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:57:26 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:57:26 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:57:26 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:57:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:57:26 INFO worker.Worker: Asked to launch executor app-20190619065726-0001/35 for TeraSort
19/06/19 06:57:26 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 06:57:26 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 06:57:26 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 06:57:26 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 06:57:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 06:57:26 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=45085" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45085" "--executor-id" "33" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619065726-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 06:57:26 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=45085" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45085" "--executor-id" "34" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619065726-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 06:57:26 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=45085" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45085" "--executor-id" "35" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619065726-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:06:26 INFO worker.Worker: Asked to kill executor app-20190619065726-0001/33
19/06/19 07:06:26 INFO worker.ExecutorRunner: Runner thread for executor app-20190619065726-0001/33 interrupted
19/06/19 07:06:26 INFO worker.ExecutorRunner: Killing process!
19/06/19 07:06:26 INFO worker.Worker: Asked to launch executor app-20190619065726-0001/118 for TeraSort
19/06/19 07:06:26 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:06:26 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:06:26 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:06:26 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:06:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:06:26 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=45085" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45085" "--executor-id" "118" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619065726-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:06:44 INFO worker.Worker: Executor app-20190619065726-0001/33 finished with state KILLED exitStatus 137
19/06/19 07:06:44 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 33
19/06/19 07:06:44 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619065726-0001, execId=33)
19/06/19 07:18:26 INFO worker.Worker: Asked to kill executor app-20190619065726-0001/34
19/06/19 07:18:26 INFO worker.ExecutorRunner: Runner thread for executor app-20190619065726-0001/34 interrupted
19/06/19 07:18:26 INFO worker.ExecutorRunner: Killing process!
19/06/19 07:18:26 INFO worker.Worker: Asked to launch executor app-20190619065726-0001/158 for TeraSort
19/06/19 07:18:26 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:18:26 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:18:26 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:18:26 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:18:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:18:26 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=45085" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45085" "--executor-id" "158" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619065726-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:18:40 INFO worker.Worker: Executor app-20190619065726-0001/34 finished with state KILLED exitStatus 137
19/06/19 07:18:40 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 34
19/06/19 07:18:40 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619065726-0001, execId=34)
19/06/19 07:42:06 INFO worker.Worker: Asked to kill executor app-20190619065726-0001/158
19/06/19 07:42:06 INFO worker.Worker: Asked to kill executor app-20190619065726-0001/35
19/06/19 07:42:06 INFO worker.ExecutorRunner: Runner thread for executor app-20190619065726-0001/158 interrupted
19/06/19 07:42:06 INFO worker.ExecutorRunner: Killing process!
19/06/19 07:42:06 INFO worker.Worker: Asked to kill executor app-20190619065726-0001/118
19/06/19 07:42:06 INFO worker.ExecutorRunner: Runner thread for executor app-20190619065726-0001/35 interrupted
19/06/19 07:42:06 INFO worker.ExecutorRunner: Killing process!
19/06/19 07:42:06 INFO worker.ExecutorRunner: Runner thread for executor app-20190619065726-0001/118 interrupted
19/06/19 07:42:06 INFO worker.ExecutorRunner: Killing process!
19/06/19 07:42:21 INFO worker.Worker: Executor app-20190619065726-0001/118 finished with state KILLED exitStatus 137
19/06/19 07:42:21 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 118
19/06/19 07:42:21 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619065726-0001, execId=118)
19/06/19 07:42:22 INFO worker.Worker: Executor app-20190619065726-0001/158 finished with state KILLED exitStatus 137
19/06/19 07:42:22 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 158
19/06/19 07:42:22 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619065726-0001, execId=158)
19/06/19 07:42:22 INFO worker.Worker: Executor app-20190619065726-0001/35 finished with state KILLED exitStatus 137
19/06/19 07:42:22 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 35
19/06/19 07:42:22 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619065726-0001, execId=35)
19/06/19 07:42:22 INFO shuffle.ExternalShuffleBlockResolver: Application app-20190619065726-0001 removed, cleanupLocalDirs = true
19/06/19 07:42:22 INFO worker.Worker: Cleaning up local directories for application app-20190619065726-0001
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/110 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/111 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/112 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/113 for TeraSort
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/114 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/115 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/116 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/117 for TeraSort
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/118 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.Worker: Asked to launch executor app-20190619075614-0002/119 for TeraSort
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls to: root
19/06/19 07:56:14 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/19 07:56:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 07:56:14 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "117" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:14 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "115" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "119" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "111" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "110" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "113" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "116" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "112" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "114" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 07:56:15 INFO worker.ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker12/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker12/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=43673" "-Dspark.network.timeout=20000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:43673" "--executor-id" "118" "--hostname" "mdc-ch1-cust4" "--cores" "1" "--app-id" "app-20190619075614-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:42319"
19/06/19 10:49:04 ERROR worker.Worker: RECEIVED SIGNAL TERM
19/06/19 10:49:05 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:49:07 WARN server.TransportChannelHandler: Exception in connection from mdc-ch1-cust4/10.1.1.4:7077
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
19/06/19 10:49:07 INFO worker.Worker: mdc-ch1-cust4:7077 Disassociated !
19/06/19 10:49:07 ERROR worker.Worker: Connection to master failed! Waiting for master to reconnect...
19/06/19 10:49:07 INFO worker.Worker: mdc-ch1-cust4.mdc.ext.hpe.com:7077 Disassociated !
19/06/19 10:49:07 ERROR worker.Worker: Connection to master failed! Waiting for master to reconnect...
19/06/19 10:49:07 INFO worker.Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
19/06/19 10:49:07 INFO worker.Worker: Connecting to master mdc-ch1-cust4:7077...
19/06/19 10:49:08 INFO client.TransportClientFactory: Found inactive connection to mdc-ch1-cust4/10.1.1.4:7077, creating a new one.
19/06/19 10:49:08 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1$$anon$1.run(Worker.scala:253)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:49:16 INFO worker.Worker: Retrying connection to master (attempt # 1)
19/06/19 10:49:16 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:49:17 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:49:25 INFO worker.Worker: Retrying connection to master (attempt # 2)
19/06/19 10:49:25 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:49:25 WARN util.Utils: Timed out waiting to forcibly kill process
19/06/19 10:49:25 WARN worker.ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@46dc1d59. This process will likely be orphaned.
19/06/19 10:49:25 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:49:25 INFO worker.Worker: Executor app-20190619075614-0002/110 finished with state FAILED message Worker shutting down
19/06/19 10:49:25 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 110
19/06/19 10:49:25 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=110)
19/06/19 10:49:26 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:49:34 INFO worker.Worker: Retrying connection to master (attempt # 3)
19/06/19 10:49:34 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:49:35 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:49:43 INFO worker.Worker: Retrying connection to master (attempt # 4)
19/06/19 10:49:43 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:49:44 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:49:46 WARN util.Utils: Timed out waiting to forcibly kill process
19/06/19 10:49:46 WARN worker.ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@5b2b228d. This process will likely be orphaned.
19/06/19 10:49:46 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:49:46 INFO worker.Worker: Executor app-20190619075614-0002/119 finished with state FAILED message Worker shutting down
19/06/19 10:49:46 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 119
19/06/19 10:49:46 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=119)
19/06/19 10:49:52 INFO worker.Worker: Retrying connection to master (attempt # 5)
19/06/19 10:49:52 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:49:53 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:50:01 INFO worker.Worker: Retrying connection to master (attempt # 6)
19/06/19 10:50:01 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:50:02 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 10:50:05 INFO worker.Worker: Executor app-20190619075614-0002/115 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:05 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 115
19/06/19 10:50:05 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=115)
19/06/19 10:50:06 WARN util.Utils: Timed out waiting to forcibly kill process
19/06/19 10:50:06 WARN worker.ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@5db32458. This process will likely be orphaned.
19/06/19 10:50:06 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:06 INFO worker.Worker: Executor app-20190619075614-0002/118 finished with state FAILED message Worker shutting down
19/06/19 10:50:06 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 118
19/06/19 10:50:06 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=118)
19/06/19 10:50:07 INFO worker.Worker: Executor app-20190619075614-0002/111 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:07 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 111
19/06/19 10:50:07 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=111)
19/06/19 10:50:11 INFO worker.Worker: Executor app-20190619075614-0002/114 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:11 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 114
19/06/19 10:50:11 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=114)
19/06/19 10:50:12 INFO worker.Worker: Executor app-20190619075614-0002/116 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:12 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 116
19/06/19 10:50:12 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=116)
19/06/19 10:50:15 INFO worker.Worker: Executor app-20190619075614-0002/113 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:15 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 113
19/06/19 10:50:15 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=113)
19/06/19 10:50:15 INFO worker.Worker: Unknown Executor app-20190619075614-0002/119 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:19 INFO worker.Worker: Unknown Executor app-20190619075614-0002/110 finished with state EXITED message Command exited with code 137 exitStatus 137
19/06/19 10:50:26 WARN util.Utils: Timed out waiting to forcibly kill process
19/06/19 10:50:26 WARN worker.ExecutorRunner: Failed to terminate process: java.lang.UNIXProcess@7bc80f9e. This process will likely be orphaned.
19/06/19 10:50:26 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:26 INFO worker.Worker: Executor app-20190619075614-0002/117 finished with state FAILED message Worker shutting down
19/06/19 10:50:26 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 117
19/06/19 10:50:26 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=117)
19/06/19 10:50:27 INFO worker.Worker: Unknown Executor app-20190619075614-0002/117 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/118 finished with state EXITED message Command exited with code 137 exitStatus 137
19/06/19 10:50:34 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:34 INFO worker.Worker: Executor app-20190619075614-0002/112 finished with state FAILED message Worker shutting down exitStatus 143
19/06/19 10:50:34 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 112
19/06/19 10:50:34 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619075614-0002, execId=112)
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/112 finished with state EXITED message Command exited with code 143 exitStatus 143
19/06/19 10:50:34 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/115 finished with state EXITED message Worker shutting down exitStatus 143
19/06/19 10:50:34 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/114 finished with state EXITED message Worker shutting down exitStatus 143
19/06/19 10:50:34 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:34 INFO worker.ExecutorRunner: Killing process!
19/06/19 10:50:34 INFO util.ShutdownHookManager: Shutdown hook called
19/06/19 10:50:34 INFO util.ShutdownHookManager: Deleting directory /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/113 finished with state EXITED message Worker shutting down exitStatus 143
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/116 finished with state EXITED message Worker shutting down exitStatus 143
19/06/19 10:50:34 INFO worker.Worker: Unknown Executor app-20190619075614-0002/111 finished with state EXITED message Worker shutting down exitStatus 143
19/06/19 10:50:35 WARN util.JavaUtils: Attempt to delete using native Unix OS command failed for path = /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c. Falling back to Java IO way
java.io.IOException: Failed to delete: /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/06/19 10:50:37 WARN util.JavaUtils: Attempt to delete using native Unix OS command failed for path = /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c/executor-bd3bcf25-96fc-4559-aa08-7e511a752eb1. Falling back to Java IO way
java.io.IOException: Failed to delete: /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c/executor-bd3bcf25-96fc-4559-aa08-7e511a752eb1
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/06/19 10:50:39 WARN util.JavaUtils: Attempt to delete using native Unix OS command failed for path = /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c/executor-bd3bcf25-96fc-4559-aa08-7e511a752eb1/blockmgr-5fde0f5d-8e74-41a4-aa64-ef6952f23f4b. Falling back to Java IO way
java.io.IOException: Failed to delete: /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c/executor-bd3bcf25-96fc-4559-aa08-7e511a752eb1/blockmgr-5fde0f5d-8e74-41a4-aa64-ef6952f23f4b
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/06/19 10:50:40 WARN util.JavaUtils: Attempt to delete using native Unix OS command failed for path = /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c/executor-bd3bcf25-96fc-4559-aa08-7e511a752eb1/blockmgr-5fde0f5d-8e74-41a4-aa64-ef6952f23f4b/0b. Falling back to Java IO way
java.io.IOException: Failed to delete: /data/spark-c639ded7-b203-4f2a-8de9-4ddced69e14c/executor-bd3bcf25-96fc-4559-aa08-7e511a752eb1/blockmgr-5fde0f5d-8e74-41a4-aa64-ef6952f23f4b/0b
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/06/19 10:50:57 INFO worker.Worker: Retrying connection to master (attempt # 7)
19/06/19 10:50:57 INFO worker.Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 10:50:57 WARN worker.Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
