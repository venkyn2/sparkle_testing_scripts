Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Spark Command: /opt/jdk1.8.0_131/jre/bin/java -cp /var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8113 spark://mdc-ch1-cust4:7077 -h mdc-ch1-cust4
========================================
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/19 02:35:52 INFO Worker: Started daemon with process name: 429816@mdc-ch1-cust4
19/06/19 02:35:52 INFO SignalUtils: Registered signal handler for TERM
19/06/19 02:35:52 INFO SignalUtils: Registered signal handler for HUP
19/06/19 02:35:52 INFO SignalUtils: Registered signal handler for INT
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 02:35:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/19 02:35:52 INFO SecurityManager: Changing view acls to: root
19/06/19 02:35:52 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:35:52 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:35:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:35:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 02:35:52 INFO Utils: Successfully started service 'sparkWorker' on port 40971.
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 02:35:53 INFO Worker: Starting Spark worker mdc-ch1-cust4:40971 with 576 cores, 22.9 TB RAM
19/06/19 02:35:53 INFO Worker: Running Spark version 2.4.0
19/06/19 02:35:53 INFO Worker: Spark home: /var/tmp/spark2.0hpcplatform/multicore/worker16
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 02:35:53 INFO Utils: Successfully started service 'WorkerUI' on port 8113.
19/06/19 02:35:53 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://mdc-ch1-cust4.mdc.ext.hpe.com:8113
19/06/19 02:35:53 INFO Worker: Connecting to master mdc-ch1-cust4:7077...
19/06/19 02:35:53 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:7077 after 20 ms (0 ms spent in bootstraps)
19/06/19 02:35:53 INFO Worker: Successfully registered with master spark://mdc-ch1-cust4.mdc.ext.hpe.com:7077
19/06/19 02:43:02 INFO Worker: Asked to launch executor app-20190619024302-0000/15 for TeraSort
19/06/19 02:43:02 INFO SecurityManager: Changing view acls to: root
19/06/19 02:43:02 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:43:02 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:43:02 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:43:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 02:43:02 INFO Worker: Asked to launch executor app-20190619024302-0000/16 for TeraSort
19/06/19 02:43:02 INFO SecurityManager: Changing view acls to: root
19/06/19 02:43:02 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:43:02 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:43:02 INFO Worker: Asked to launch executor app-20190619024302-0000/17 for TeraSort
19/06/19 02:43:02 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:43:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 02:43:02 INFO SecurityManager: Changing view acls to: root
19/06/19 02:43:02 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:43:02 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:43:02 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:43:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 02:43:02 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39331" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39331" "--executor-id" "16" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619024302-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 02:43:02 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39331" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39331" "--executor-id" "17" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619024302-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 02:43:02 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39331" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39331" "--executor-id" "15" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619024302-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 02:43:10 INFO Worker: Asked to kill executor app-20190619024302-0000/17
19/06/19 02:43:10 INFO Worker: Asked to kill executor app-20190619024302-0000/16
19/06/19 02:43:10 INFO Worker: Asked to kill executor app-20190619024302-0000/15
19/06/19 02:43:10 INFO ExecutorRunner: Runner thread for executor app-20190619024302-0000/15 interrupted
19/06/19 02:43:10 INFO ExecutorRunner: Runner thread for executor app-20190619024302-0000/17 interrupted
19/06/19 02:43:10 INFO ExecutorRunner: Runner thread for executor app-20190619024302-0000/16 interrupted
19/06/19 02:43:10 INFO ExecutorRunner: Killing process!
19/06/19 02:43:10 INFO ExecutorRunner: Killing process!
19/06/19 02:43:10 INFO ExecutorRunner: Killing process!
19/06/19 02:43:11 INFO Worker: Executor app-20190619024302-0000/17 finished with state KILLED exitStatus 143
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 17
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619024302-0000, execId=17)
19/06/19 02:43:11 INFO Worker: Executor app-20190619024302-0000/15 finished with state KILLED exitStatus 143
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 15
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619024302-0000, execId=15)
19/06/19 02:43:11 INFO Worker: Executor app-20190619024302-0000/16 finished with state KILLED exitStatus 143
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 16
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619024302-0000, execId=16)
19/06/19 02:43:11 INFO ExternalShuffleBlockResolver: Application app-20190619024302-0000 removed, cleanupLocalDirs = true
19/06/19 02:43:11 INFO Worker: Cleaning up local directories for application app-20190619024302-0000
19/06/19 02:45:24 INFO Worker: Asked to launch executor app-20190619024524-0001/15 for TeraSort
19/06/19 02:45:24 INFO SecurityManager: Changing view acls to: root
19/06/19 02:45:24 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:45:24 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:45:24 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:45:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 02:45:24 INFO Worker: Asked to launch executor app-20190619024524-0001/16 for TeraSort
19/06/19 02:45:24 INFO SecurityManager: Changing view acls to: root
19/06/19 02:45:24 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:45:24 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:45:24 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:45:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 02:45:24 INFO Worker: Asked to launch executor app-20190619024524-0001/17 for TeraSort
19/06/19 02:45:24 INFO SecurityManager: Changing view acls to: root
19/06/19 02:45:24 INFO SecurityManager: Changing modify acls to: root
19/06/19 02:45:24 INFO SecurityManager: Changing view acls groups to: 
19/06/19 02:45:24 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 02:45:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 02:45:24 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-Dspark.driver.port=46379" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:46379" "--executor-id" "16" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619024524-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 02:45:24 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-Dspark.driver.port=46379" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:46379" "--executor-id" "15" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619024524-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 02:45:24 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-Dspark.driver.port=46379" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:46379" "--executor-id" "17" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619024524-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 02:52:13 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker16/work/app-20190619024524-0001/17/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 02:52:13 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker16/work/app-20190619024524-0001/16/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 02:54:51 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker16/work/app-20190619024524-0001/15/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 02:55:25 INFO Worker: Asked to kill executor app-20190619024524-0001/17
19/06/19 02:55:25 INFO Worker: Asked to kill executor app-20190619024524-0001/16
19/06/19 02:55:25 INFO ExecutorRunner: Runner thread for executor app-20190619024524-0001/17 interrupted
19/06/19 02:55:25 INFO ExecutorRunner: Killing process!
19/06/19 02:55:25 INFO ExecutorRunner: Runner thread for executor app-20190619024524-0001/16 interrupted
19/06/19 02:55:25 INFO ExecutorRunner: Killing process!
19/06/19 02:55:25 INFO Worker: Asked to kill executor app-20190619024524-0001/15
19/06/19 02:55:25 INFO ExecutorRunner: Runner thread for executor app-20190619024524-0001/15 interrupted
19/06/19 02:55:25 INFO ExecutorRunner: Killing process!
19/06/19 02:55:27 INFO Worker: Executor app-20190619024524-0001/15 finished with state KILLED exitStatus 143
19/06/19 02:55:27 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 15
19/06/19 02:55:27 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619024524-0001, execId=15)
19/06/19 02:55:29 INFO Worker: Executor app-20190619024524-0001/17 finished with state KILLED exitStatus 143
19/06/19 02:55:29 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 17
19/06/19 02:55:29 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619024524-0001, execId=17)
19/06/19 02:55:29 INFO Worker: Executor app-20190619024524-0001/16 finished with state KILLED exitStatus 143
19/06/19 02:55:29 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 16
19/06/19 02:55:29 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619024524-0001, execId=16)
19/06/19 02:55:29 INFO ExternalShuffleBlockResolver: Application app-20190619024524-0001 removed, cleanupLocalDirs = true
19/06/19 02:55:29 INFO Worker: Cleaning up local directories for application app-20190619024524-0001
19/06/19 03:06:31 INFO Worker: Asked to launch executor app-20190619030631-0002/15 for TeraSort
19/06/19 03:06:31 INFO Worker: Asked to launch executor app-20190619030631-0002/16 for TeraSort
19/06/19 03:06:31 INFO SecurityManager: Changing view acls to: root
19/06/19 03:06:31 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:06:31 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:06:31 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:06:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:06:31 INFO SecurityManager: Changing view acls to: root
19/06/19 03:06:31 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:06:31 INFO Worker: Asked to launch executor app-20190619030631-0002/17 for TeraSort
19/06/19 03:06:31 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:06:31 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:06:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:06:31 INFO SecurityManager: Changing view acls to: root
19/06/19 03:06:31 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:06:31 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:06:31 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:06:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:06:31 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=37637" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:37637" "--executor-id" "15" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619030631-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 03:06:31 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=37637" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:37637" "--executor-id" "17" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619030631-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 03:06:31 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker16/conf:/var/tmp/spark2.0hpcplatform/multicore/worker16/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=37637" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:37637" "--executor-id" "16" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619030631-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:40971"
19/06/19 03:10:47 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker16/work/app-20190619030631-0002/17/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 03:12:14 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker16/work/app-20190619030631-0002/16/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 03:14:51 INFO Worker: Asked to kill executor app-20190619030631-0002/17
19/06/19 03:14:51 INFO Worker: Asked to kill executor app-20190619030631-0002/16
19/06/19 03:14:51 INFO Worker: Asked to kill executor app-20190619030631-0002/15
19/06/19 03:14:51 INFO ExecutorRunner: Runner thread for executor app-20190619030631-0002/17 interrupted
19/06/19 03:14:51 INFO ExecutorRunner: Runner thread for executor app-20190619030631-0002/15 interrupted
19/06/19 03:14:51 INFO ExecutorRunner: Killing process!
19/06/19 03:14:51 INFO ExecutorRunner: Killing process!
19/06/19 03:14:51 INFO ExecutorRunner: Runner thread for executor app-20190619030631-0002/16 interrupted
19/06/19 03:14:51 INFO ExecutorRunner: Killing process!
19/06/19 03:14:54 INFO Worker: Executor app-20190619030631-0002/16 finished with state KILLED exitStatus 143
19/06/19 03:14:54 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 16
19/06/19 03:14:54 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619030631-0002, execId=16)
19/06/19 03:14:55 INFO Worker: Executor app-20190619030631-0002/17 finished with state KILLED exitStatus 143
19/06/19 03:14:55 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 17
19/06/19 03:14:55 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619030631-0002, execId=17)
19/06/19 03:14:56 INFO Worker: Executor app-20190619030631-0002/15 finished with state KILLED exitStatus 143
19/06/19 03:14:56 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 15
19/06/19 03:14:56 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619030631-0002, execId=15)
19/06/19 03:14:56 INFO ExternalShuffleBlockResolver: Application app-20190619030631-0002 removed, cleanupLocalDirs = true
19/06/19 03:14:56 INFO Worker: Cleaning up local directories for application app-20190619030631-0002
19/06/19 03:33:26 ERROR Worker: RECEIVED SIGNAL TERM
19/06/19 03:33:26 INFO ShutdownHookManager: Shutdown hook called
19/06/19 03:33:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-5d4193bc-9d17-4a9b-bfe9-8270e7823d71
