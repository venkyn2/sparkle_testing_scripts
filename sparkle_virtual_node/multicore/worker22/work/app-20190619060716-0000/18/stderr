Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker22/conf:/var/tmp/spark2.0hpcplatform/multicore/worker22/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=42315" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:42315" "--executor-id" "18" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619060716-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:40715"
========================================

Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/19 06:07:17 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 190843@mdc-ch1-cust4
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for TERM
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for HUP
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for INT
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/19 06:07:17 INFO SecurityManager: Changing view acls to: root,nnnnnven
19/06/19 06:07:17 INFO SecurityManager: Changing modify acls to: root,nnnnnven
19/06/19 06:07:17 INFO SecurityManager: Changing view acls groups to: 
19/06/19 06:07:17 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 06:07:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:18 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 65 ms (0 ms spent in bootstraps)
19/06/19 06:07:18 WARN SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/06/19 06:07:18 INFO SecurityManager: Changing view acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing view acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/19 06:07:18 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 3 ms (0 ms spent in bootstraps)
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:20 INFO DiskBlockManager: Created local directory at /tmp/spark-50ae101c-b076-4efc-bb22-cc5e8857e1fb/executor-44fed3f3-d6d3-417a-b504-014cfdc2ced0/blockmgr-e0b61451-e553-4d5c-bfa6-577712d46c07
19/06/19 06:07:20 INFO MemoryStore: MemoryStore started with capacity 4.1 GB
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:42315
19/06/19 06:07:21 INFO WorkerWatcher: Connecting to worker spark://Worker@mdc-ch1-cust4:40715
19/06/19 06:07:21 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:40715 after 161 ms (0 ms spent in bootstraps)
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/06/19 06:07:21 INFO Executor: Starting executor ID 18 on host mdc-ch1-cust4
19/06/19 06:07:21 INFO WorkerWatcher: Successfully connected to spark://Worker@mdc-ch1-cust4:40715
19/06/19 06:07:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39053.
19/06/19 06:07:21 INFO NettyBlockTransferService: Server created on mdc-ch1-cust4:39053
19/06/19 06:07:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/19 06:07:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(18, mdc-ch1-cust4, 39053, None)
19/06/19 06:07:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(18, mdc-ch1-cust4, 39053, None)
19/06/19 06:07:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(18, mdc-ch1-cust4, 39053, None)
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Got assigned task 20
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Got assigned task 21
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Got assigned task 22
19/06/19 06:07:21 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Got assigned task 23
19/06/19 06:07:21 INFO Executor: Running task 22.0 in stage 0.0 (TID 22)
19/06/19 06:07:21 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
19/06/19 06:07:21 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
19/06/19 06:07:21 INFO Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:42315/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1560949636224
19/06/19 06:07:21 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 7 ms (0 ms spent in bootstraps)
19/06/19 06:07:21 INFO Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:42315/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /tmp/spark-50ae101c-b076-4efc-bb22-cc5e8857e1fb/executor-44fed3f3-d6d3-417a-b504-014cfdc2ced0/spark-0b5abf77-0492-40e8-8d98-099a25631647/fetchFileTemp8796999059779574513.tmp
19/06/19 06:07:22 INFO Utils: Copying /tmp/spark-50ae101c-b076-4efc-bb22-cc5e8857e1fb/executor-44fed3f3-d6d3-417a-b504-014cfdc2ced0/spark-0b5abf77-0492-40e8-8d98-099a25631647/-11144796181560949636224_cache to /var/tmp/spark2.0hpcplatform/multicore/worker22/work/app-20190619060716-0000/18/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/06/19 06:07:22 INFO Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker22/work/app-20190619060716-0000/18/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/06/19 06:07:22 INFO TorrentBroadcast: Started reading broadcast variable 1
19/06/19 06:07:22 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:36105 after 2 ms (0 ms spent in bootstraps)
19/06/19 06:07:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/06/19 06:07:22 INFO TorrentBroadcast: Reading broadcast variable 1 took 228 ms
19/06/19 06:07:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/06/19 06:07:22 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:21474836480+1073741824
19/06/19 06:07:22 INFO TorrentBroadcast: Started reading broadcast variable 0
19/06/19 06:07:22 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:24696061952+1073741824
19/06/19 06:07:22 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:22548578304+1073741824
19/06/19 06:07:22 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:46413 after 3 ms (0 ms spent in bootstraps)
19/06/19 06:07:22 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00000:23622320128+1073741824
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/06/19 06:07:23 INFO TorrentBroadcast: Reading broadcast variable 0 took 772 ms
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/06/19 06:08:34 INFO ShuffleExternalSorter: Thread 94 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:34 INFO ShuffleExternalSorter: Thread 91 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:37 INFO ShuffleExternalSorter: Thread 92 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:41 INFO ShuffleExternalSorter: Thread 93 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:10:16 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/06/19 06:10:16 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
