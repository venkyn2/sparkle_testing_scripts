Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker23/conf:/var/tmp/spark2.0hpcplatform/multicore/worker23/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=42315" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:42315" "--executor-id" "68" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619060716-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:46855"
========================================

Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/19 06:07:17 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 205271@mdc-ch1-cust4
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for TERM
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for HUP
19/06/19 06:07:17 INFO SignalUtils: Registered signal handler for INT
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/19 06:07:18 INFO SecurityManager: Changing view acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing view acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:18 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 89 ms (0 ms spent in bootstraps)
19/06/19 06:07:18 WARN SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/06/19 06:07:18 INFO SecurityManager: Changing view acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls to: root,nnnnnven
19/06/19 06:07:18 INFO SecurityManager: Changing view acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 06:07:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/19 06:07:19 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 6 ms (0 ms spent in bootstraps)
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 06:07:21 INFO DiskBlockManager: Created local directory at /tmp/spark-419fe787-b78e-4428-a099-0abaa495458a/executor-ff192874-2de8-43ec-a679-48f1993fc591/blockmgr-d837379c-fd3a-46a4-9c16-a4a42df6dfcb
19/06/19 06:07:21 INFO MemoryStore: MemoryStore started with capacity 4.1 GB
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:42315
19/06/19 06:07:21 INFO WorkerWatcher: Connecting to worker spark://Worker@mdc-ch1-cust4:46855
19/06/19 06:07:21 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:46855 after 12 ms (0 ms spent in bootstraps)
19/06/19 06:07:21 INFO WorkerWatcher: Successfully connected to spark://Worker@mdc-ch1-cust4:46855
19/06/19 06:07:21 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/06/19 06:07:21 INFO Executor: Starting executor ID 68 on host mdc-ch1-cust4
19/06/19 06:07:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46861.
19/06/19 06:07:22 INFO NettyBlockTransferService: Server created on mdc-ch1-cust4:46861
19/06/19 06:07:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/19 06:07:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(68, mdc-ch1-cust4, 46861, None)
19/06/19 06:07:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(68, mdc-ch1-cust4, 46861, None)
19/06/19 06:07:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(68, mdc-ch1-cust4, 46861, None)
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 156
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 157
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 158
19/06/19 06:07:22 INFO CoarseGrainedExecutorBackend: Got assigned task 159
19/06/19 06:07:22 INFO Executor: Running task 157.0 in stage 0.0 (TID 157)
19/06/19 06:07:22 INFO Executor: Running task 159.0 in stage 0.0 (TID 159)
19/06/19 06:07:22 INFO Executor: Running task 156.0 in stage 0.0 (TID 156)
19/06/19 06:07:22 INFO Executor: Running task 158.0 in stage 0.0 (TID 158)
19/06/19 06:07:22 INFO Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:42315/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1560949636224
19/06/19 06:07:22 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:42315 after 2 ms (0 ms spent in bootstraps)
19/06/19 06:07:22 INFO Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:42315/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /tmp/spark-419fe787-b78e-4428-a099-0abaa495458a/executor-ff192874-2de8-43ec-a679-48f1993fc591/spark-2bc89bdd-0275-4efa-ad26-cc88119eb8bf/fetchFileTemp9014612625480103578.tmp
19/06/19 06:07:22 INFO Utils: Copying /tmp/spark-419fe787-b78e-4428-a099-0abaa495458a/executor-ff192874-2de8-43ec-a679-48f1993fc591/spark-2bc89bdd-0275-4efa-ad26-cc88119eb8bf/-11144796181560949636224_cache to /var/tmp/spark2.0hpcplatform/multicore/worker23/work/app-20190619060716-0000/68/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/06/19 06:07:22 INFO Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker23/work/app-20190619060716-0000/68/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/06/19 06:07:22 INFO TorrentBroadcast: Started reading broadcast variable 1
19/06/19 06:07:22 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:33689 after 4 ms (0 ms spent in bootstraps)
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/06/19 06:07:23 INFO TorrentBroadcast: Reading broadcast variable 1 took 170 ms
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00004:6442450944+1073741824
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00004:4294967296+1073741824
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00004:7516192768+1073741824
19/06/19 06:07:23 INFO NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven1000G/HSsort-input/part-r-00004:5368709120+1073741824
19/06/19 06:07:23 INFO TorrentBroadcast: Started reading broadcast variable 0
19/06/19 06:07:23 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:42581 after 2 ms (0 ms spent in bootstraps)
19/06/19 06:07:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/06/19 06:07:23 INFO TorrentBroadcast: Reading broadcast variable 0 took 97 ms
19/06/19 06:07:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/06/19 06:08:38 INFO ShuffleExternalSorter: Thread 92 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:39 INFO ShuffleExternalSorter: Thread 91 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:40 INFO ShuffleExternalSorter: Thread 89 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:08:45 INFO ShuffleExternalSorter: Thread 90 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/19 06:10:16 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/06/19 06:10:16 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
