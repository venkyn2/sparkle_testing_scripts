Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker3/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker3/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.rpc.numRetries=5" "-Dspark.driver.port=35591" "-Dspark.network.timeout=40000" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35591" "--executor-id" "85" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190620092631-0011" "--worker-url" "spark://Worker@mdc-ch1-cust4:37279"
========================================

19/06/20 09:26:32 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 90843@mdc-ch1-cust4
19/06/20 09:26:32 INFO util.SignalUtils: Registered signal handler for TERM
19/06/20 09:26:32 INFO util.SignalUtils: Registered signal handler for HUP
19/06/20 09:26:32 INFO util.SignalUtils: Registered signal handler for INT
19/06/20 09:26:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/20 09:26:32 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/06/20 09:26:32 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/06/20 09:26:32 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/20 09:26:32 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/20 09:26:32 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/20 09:26:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:35591 after 81 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 WARN spark.SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/06/20 09:26:33 WARN spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
19/06/20 09:26:33 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/06/20 09:26:33 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/06/20 09:26:33 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/20 09:26:33 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/20 09:26:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:35591 after 2 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO storage.DiskBlockManager: Created local directory at /data/spark-116e9f26-d387-405c-86a0-7964901ec4ee/executor-1efacf14-0661-4c05-bdd2-6a40e5b2ca0d/blockmgr-8cbee2e5-a150-4e4f-a8b3-7d2d3bf6e868
19/06/20 09:26:33 INFO memory.MemoryStore: MemoryStore started with capacity 4.1 GB
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35591
19/06/20 09:26:33 INFO worker.WorkerWatcher: Connecting to worker spark://Worker@mdc-ch1-cust4:37279
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:37279 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO worker.WorkerWatcher: Successfully connected to spark://Worker@mdc-ch1-cust4:37279
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
19/06/20 09:26:33 INFO executor.Executor: Starting executor ID 85 on host mdc-ch1-cust4
19/06/20 09:26:33 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45965.
19/06/20 09:26:33 INFO netty.NettyBlockTransferService: Server created on mdc-ch1-cust4:45965
19/06/20 09:26:33 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/20 09:26:33 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(85, mdc-ch1-cust4, 45965, None)
19/06/20 09:26:33 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(85, mdc-ch1-cust4, 45965, None)
19/06/20 09:26:33 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(85, mdc-ch1-cust4, 45965, None)
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 268
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 269
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 270
19/06/20 09:26:33 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 271
19/06/20 09:26:33 INFO executor.Executor: Running task 268.0 in stage 0.0 (TID 268)
19/06/20 09:26:33 INFO executor.Executor: Running task 269.0 in stage 0.0 (TID 269)
19/06/20 09:26:33 INFO executor.Executor: Running task 271.0 in stage 0.0 (TID 271)
19/06/20 09:26:33 INFO executor.Executor: Running task 270.0 in stage 0.0 (TID 270)
19/06/20 09:26:33 INFO executor.Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:35591/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1561047991720
19/06/20 09:26:33 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:35591 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:33 INFO util.Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:35591/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /data/spark-116e9f26-d387-405c-86a0-7964901ec4ee/executor-1efacf14-0661-4c05-bdd2-6a40e5b2ca0d/spark-5034f36a-1533-4f9e-b13c-dc6072eb1a51/fetchFileTemp8941591753142443342.tmp
19/06/20 09:26:33 INFO util.Utils: Copying /data/spark-116e9f26-d387-405c-86a0-7964901ec4ee/executor-1efacf14-0661-4c05-bdd2-6a40e5b2ca0d/spark-5034f36a-1533-4f9e-b13c-dc6072eb1a51/-339060041561047991720_cache to /var/tmp/spark2.0hpcplatform/multicore/worker3/work/app-20190620092631-0011/85/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/06/20 09:26:33 INFO executor.Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker3/work/app-20190620092631-0011/85/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/06/20 09:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
19/06/20 09:26:34 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:32855 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 4.1 GB)
19/06/20 09:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 100 ms
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 4.1 GB)
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00003:48318382080+1073741824
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00003:47244640256+1073741824
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00003:49392123904+1073741824
19/06/20 09:26:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00003:46170898432+1073741824
19/06/20 09:26:34 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
19/06/20 09:26:34 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:32905 after 1 ms (0 ms spent in bootstraps)
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 4.1 GB)
19/06/20 09:26:34 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 56 ms
19/06/20 09:26:34 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.5 KB, free 4.1 GB)
19/06/20 09:40:07 INFO sort.ShuffleExternalSorter: Thread 72 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:41:04 INFO sort.ShuffleExternalSorter: Thread 71 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:43:06 INFO executor.Executor: Finished task 271.0 in stage 0.0 (TID 271). 2958 bytes result sent to driver
19/06/20 09:43:06 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 973
19/06/20 09:43:06 INFO executor.Executor: Running task 973.0 in stage 0.0 (TID 973)
19/06/20 09:43:06 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00012:78383153152+1073741824
19/06/20 09:44:26 INFO executor.Executor: Finished task 270.0 in stage 0.0 (TID 270). 2958 bytes result sent to driver
19/06/20 09:44:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1043
19/06/20 09:44:26 INFO executor.Executor: Running task 1043.0 in stage 0.0 (TID 1043)
19/06/20 09:44:26 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00013:73014444032+1073741824
19/06/20 09:52:03 INFO sort.ShuffleExternalSorter: Thread 70 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:53:34 INFO executor.Executor: Finished task 269.0 in stage 0.0 (TID 269). 2958 bytes result sent to driver
19/06/20 09:53:34 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1445
19/06/20 09:53:34 INFO executor.Executor: Running task 1445.0 in stage 0.0 (TID 1445)
19/06/20 09:53:34 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00019:21474836480+1073741824
19/06/20 09:53:37 INFO sort.ShuffleExternalSorter: Thread 70 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:53:48 INFO executor.Executor: Finished task 1445.0 in stage 0.0 (TID 1445). 2958 bytes result sent to driver
19/06/20 09:53:48 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1463
19/06/20 09:53:48 INFO executor.Executor: Running task 1463.0 in stage 0.0 (TID 1463)
19/06/20 09:53:48 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00019:40802189312+1073741824
19/06/20 09:53:52 INFO sort.ShuffleExternalSorter: Thread 70 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:54:02 INFO executor.Executor: Finished task 1463.0 in stage 0.0 (TID 1463). 2915 bytes result sent to driver
19/06/20 09:54:02 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1477
19/06/20 09:54:02 INFO executor.Executor: Running task 1477.0 in stage 0.0 (TID 1477)
19/06/20 09:54:02 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00019:55834574848+1073741824
19/06/20 09:54:06 INFO sort.ShuffleExternalSorter: Thread 70 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:54:16 INFO executor.Executor: Finished task 1477.0 in stage 0.0 (TID 1477). 2958 bytes result sent to driver
19/06/20 09:54:16 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1497
19/06/20 09:54:16 INFO executor.Executor: Running task 1497.0 in stage 0.0 (TID 1497)
19/06/20 09:54:16 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00019:77309411328+1073741824
19/06/20 09:54:20 INFO sort.ShuffleExternalSorter: Thread 70 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:54:29 INFO executor.Executor: Finished task 1497.0 in stage 0.0 (TID 1497). 2958 bytes result sent to driver
19/06/20 09:54:29 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1512
19/06/20 09:54:29 INFO executor.Executor: Running task 1512.0 in stage 0.0 (TID 1512)
19/06/20 09:54:29 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00020:12884901888+1073741824
19/06/20 09:55:04 INFO sort.ShuffleExternalSorter: Thread 69 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:57:53 INFO sort.ShuffleExternalSorter: Thread 72 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 09:58:30 INFO executor.Executor: Finished task 268.0 in stage 0.0 (TID 268). 2958 bytes result sent to driver
19/06/20 09:58:30 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1671
19/06/20 09:58:30 INFO executor.Executor: Running task 1671.0 in stage 0.0 (TID 1671)
19/06/20 09:58:30 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00022:22548578304+1073741824
19/06/20 09:59:45 INFO executor.Executor: Finished task 973.0 in stage 0.0 (TID 973). 2958 bytes result sent to driver
19/06/20 09:59:45 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1779
19/06/20 09:59:45 INFO executor.Executor: Running task 1779.0 in stage 0.0 (TID 1779)
19/06/20 09:59:45 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00023:57982058496+1073741824
19/06/20 09:59:46 INFO sort.ShuffleExternalSorter: Thread 71 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 10:00:44 INFO executor.Executor: Finished task 1043.0 in stage 0.0 (TID 1043). 2958 bytes result sent to driver
19/06/20 10:00:44 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1849
19/06/20 10:00:44 INFO executor.Executor: Running task 1849.0 in stage 0.0 (TID 1849)
19/06/20 10:00:44 INFO rdd.NewHadoopRDD: Input split: hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/part-r-00024:52613349376+1073741824
19/06/20 10:07:30 INFO sort.ShuffleExternalSorter: Thread 71 spilling sort data of 1024.0 MB to disk (0  time so far)
19/06/20 10:08:03 INFO executor.Executor: Finished task 1849.0 in stage 0.0 (TID 1849). 2958 bytes result sent to driver
19/06/20 10:08:43 INFO sort.ShuffleExternalSorter: Thread 72 spilling sort data of 1344.0 MB to disk (0  time so far)
19/06/20 10:09:02 INFO executor.Executor: Finished task 1779.0 in stage 0.0 (TID 1779). 2958 bytes result sent to driver
19/06/20 10:09:36 INFO executor.Executor: Finished task 1512.0 in stage 0.0 (TID 1512). 2829 bytes result sent to driver
19/06/20 10:10:29 INFO executor.Executor: Finished task 1671.0 in stage 0.0 (TID 1671). 2872 bytes result sent to driver
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1896
19/06/20 10:14:31 INFO executor.Executor: Running task 21.0 in stage 1.0 (TID 1896)
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1996
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2096
19/06/20 10:14:31 INFO executor.Executor: Running task 121.0 in stage 1.0 (TID 1996)
19/06/20 10:14:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2196
19/06/20 10:14:31 INFO executor.Executor: Running task 221.0 in stage 1.0 (TID 2096)
19/06/20 10:14:31 INFO executor.Executor: Running task 321.0 in stage 1.0 (TID 2196)
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
19/06/20 10:14:31 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
19/06/20 10:14:31 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:39129 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:31 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 25.0 KB, free 4.1 GB)
19/06/20 10:14:31 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 22 ms
19/06/20 10:14:31 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 69.4 KB, free 4.1 GB)
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@mdc-ch1-cust4.mdc.ext.hpe.com:35591)
19/06/20 10:14:31 INFO spark.MapOutputTrackerWorker: Got the output locations
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:14:32 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:36557 after 17 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:35497 after 18 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:39023 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:43493 after 24 ms (0 ms spent in bootstraps)
19/06/20 10:14:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:35275 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 WARN client.TransportClientFactory: DNS resolution for mdc-ch8-cust4/10.1.8.4:42161 took 5007 ms
19/06/20 10:14:37 WARN client.TransportClientFactory: DNS resolution for mdc-ch3-cust4/10.1.3.4:36079 took 5008 ms
19/06/20 10:14:37 WARN client.TransportClientFactory: DNS resolution for mdc-ch8-cust4/10.1.8.4:33191 took 4982 ms
19/06/20 10:14:37 WARN client.TransportClientFactory: DNS resolution for mdc-ch3-cust4/10.1.3.4:33351 took 4984 ms
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:42161 after 10 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:38379 after 32 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:33191 after 47 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:33351 after 56 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:36079 after 60 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:40777 after 21 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:43039 after 33 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:33457 after 54 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:33659 after 68 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:37161 after 15 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:32871 after 60 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:45875 after 22 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:34241 after 28 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:43651 after 4 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:46775 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:41251 after 61 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:39063 after 37 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:42735 after 46 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:37741 after 55 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:43327 after 62 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:45869 after 57 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:42049 after 15 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:33113 after 36 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 5383 ms
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:46333 after 27 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:41811 after 149 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 5388 ms
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:46487 after 61 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:46747 after 42 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:37961 after 62 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:38137 after 47 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO storage.ShuffleBlockFetcherIterator: Started 12 remote fetches in 5460 ms
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:41657 after 53 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:45039 after 32 ms (0 ms spent in bootstraps)
19/06/20 10:14:37 INFO storage.ShuffleBlockFetcherIterator: Started 13 remote fetches in 5512 ms
19/06/20 10:14:38 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:45427 after 89 ms (0 ms spent in bootstraps)
19/06/20 10:14:38 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:40573 after 117 ms (0 ms spent in bootstraps)
19/06/20 10:14:38 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:42171 after 62 ms (0 ms spent in bootstraps)
19/06/20 10:14:38 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:40313 after 27 ms (0 ms spent in bootstraps)
19/06/20 10:14:39 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:41651 after 56 ms (0 ms spent in bootstraps)
19/06/20 10:14:39 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:43487 after 76 ms (0 ms spent in bootstraps)
19/06/20 10:14:40 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:37195 after 1114 ms (0 ms spent in bootstraps)
19/06/20 10:14:41 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:38193 after 114 ms (0 ms spent in bootstraps)
19/06/20 10:14:41 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:35777 after 27 ms (0 ms spent in bootstraps)
19/06/20 10:14:42 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:37193 after 106 ms (0 ms spent in bootstraps)
19/06/20 10:14:43 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:43807 after 59 ms (0 ms spent in bootstraps)
19/06/20 10:14:44 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:39285 after 57 ms (0 ms spent in bootstraps)
19/06/20 10:14:46 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:33717 after 12 ms (0 ms spent in bootstraps)
19/06/20 10:14:47 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:45911 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:14:47 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:32975 after 36 ms (0 ms spent in bootstraps)
19/06/20 10:14:48 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:35265 after 35 ms (0 ms spent in bootstraps)
19/06/20 10:14:49 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:37233 after 19 ms (0 ms spent in bootstraps)
19/06/20 10:14:49 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:37409 after 85 ms (0 ms spent in bootstraps)
19/06/20 10:14:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:35209 after 79 ms (0 ms spent in bootstraps)
19/06/20 10:14:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:40783 after 92 ms (0 ms spent in bootstraps)
19/06/20 10:14:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:33807 after 51 ms (0 ms spent in bootstraps)
19/06/20 10:14:51 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:38665 after 52 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:34997 after 11 ms (0 ms spent in bootstraps)
19/06/20 10:14:52 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:41545 after 47 ms (0 ms spent in bootstraps)
19/06/20 10:14:53 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:33347 after 18 ms (0 ms spent in bootstraps)
19/06/20 10:14:55 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:37727 after 29 ms (0 ms spent in bootstraps)
19/06/20 10:14:57 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:38551 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:14:58 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:39789 after 37 ms (0 ms spent in bootstraps)
19/06/20 10:14:59 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:44941 after 53 ms (0 ms spent in bootstraps)
19/06/20 10:15:00 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:38915 after 62 ms (0 ms spent in bootstraps)
19/06/20 10:15:00 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:40803 after 2 ms (0 ms spent in bootstraps)
19/06/20 10:15:01 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:36127 after 47 ms (0 ms spent in bootstraps)
19/06/20 10:15:04 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:39883 after 50 ms (0 ms spent in bootstraps)
19/06/20 10:15:05 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:44295 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:15:05 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:42049 after 12 ms (0 ms spent in bootstraps)
19/06/20 10:15:08 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:41699 after 59 ms (0 ms spent in bootstraps)
19/06/20 10:15:09 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:35145 after 3 ms (0 ms spent in bootstraps)
19/06/20 10:15:09 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:34507 after 58 ms (0 ms spent in bootstraps)
19/06/20 10:15:12 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:39819 after 13 ms (0 ms spent in bootstraps)
19/06/20 10:15:28 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:33877 after 134 ms (0 ms spent in bootstraps)
19/06/20 10:15:29 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:42033 after 73 ms (0 ms spent in bootstraps)
19/06/20 10:15:30 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:38259 after 25 ms (0 ms spent in bootstraps)
19/06/20 10:15:30 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:37187 after 34 ms (0 ms spent in bootstraps)
19/06/20 10:15:32 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:39889 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:15:36 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:36153 after 2 ms (0 ms spent in bootstraps)
19/06/20 10:15:41 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:46425 after 7 ms (0 ms spent in bootstraps)
19/06/20 10:15:41 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:36525 after 75 ms (0 ms spent in bootstraps)
19/06/20 10:15:44 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:43867 after 111 ms (0 ms spent in bootstraps)
19/06/20 10:15:46 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:40923 after 78 ms (0 ms spent in bootstraps)
19/06/20 10:15:48 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:43903 after 5 ms (0 ms spent in bootstraps)
19/06/20 10:15:48 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:33833 after 55 ms (0 ms spent in bootstraps)
19/06/20 10:16:06 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:33421 after 38 ms (0 ms spent in bootstraps)
19/06/20 10:16:11 INFO client.TransportClientFactory: Successfully created connection to mdc-ch8-cust4/10.1.8.4:42461 after 32 ms (0 ms spent in bootstraps)
19/06/20 10:16:49 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:46601 after 14 ms (0 ms spent in bootstraps)
19/06/20 10:16:50 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:35655 after 78 ms (0 ms spent in bootstraps)
19/06/20 10:16:50 INFO client.TransportClientFactory: Successfully created connection to mdc-ch5-cust4/10.1.5.4:40437 after 13 ms (0 ms spent in bootstraps)
19/06/20 10:16:53 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:36615 after 1 ms (0 ms spent in bootstraps)
19/06/20 10:16:56 INFO client.TransportClientFactory: Successfully created connection to mdc-ch6-cust4/10.1.6.4:41471 after 50 ms (0 ms spent in bootstraps)
19/06/20 10:16:57 INFO collection.ExternalSorter: Thread 102 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:16:57 INFO collection.ExternalSorter: Thread 100 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:16:59 INFO collection.ExternalSorter: Thread 101 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:17:02 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:42325 after 9 ms (0 ms spent in bootstraps)
19/06/20 10:17:02 INFO collection.ExternalSorter: Thread 103 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:19:26 INFO client.TransportClientFactory: Successfully created connection to mdc-ch7-cust4/10.1.7.4:38911 after 3 ms (0 ms spent in bootstraps)
19/06/20 10:19:26 INFO client.TransportClientFactory: Successfully created connection to mdc-ch3-cust4/10.1.3.4:39023 after 4 ms (0 ms spent in bootstraps)
19/06/20 10:22:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:22:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:22:46 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000121_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000121
19/06/20 10:22:46 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000121_0: Committed
19/06/20 10:22:46 INFO executor.Executor: Finished task 121.0 in stage 1.0 (TID 1996). 1342 bytes result sent to driver
19/06/20 10:22:46 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2305
19/06/20 10:22:46 INFO executor.Executor: Running task 430.0 in stage 1.0 (TID 2305)
19/06/20 10:22:46 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:22:46 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 9 ms
19/06/20 10:23:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:23:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:23:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:23:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:23:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:23:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:24:54 INFO collection.ExternalSorter: Thread 101 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:24:54 WARN hdfs.DFSClient: DataStreamer Exception
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:508)
19/06/20 10:24:54 WARN hdfs.DFSClient: DataStreamer Exception
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:508)
19/06/20 10:24:54 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073746118_5294
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:24:54 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:24:54 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073746116_5292
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:24:54 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073746020_5196
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:24:54 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000321_0 aborted.
19/06/20 10:24:54 ERROR executor.Executor: Exception in task 321.0 in stage 1.0 (TID 2196)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:24:54 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:24:54 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:24:54 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000221_0 aborted.
19/06/20 10:24:54 ERROR executor.Executor: Exception in task 221.0 in stage 1.0 (TID 2096)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:24:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2516
19/06/20 10:24:54 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_000021_0 aborted.
19/06/20 10:24:54 ERROR executor.Executor: Exception in task 21.0 in stage 1.0 (TID 1896)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:24:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2517
19/06/20 10:24:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2518
19/06/20 10:24:54 INFO executor.Executor: Running task 321.1 in stage 1.0 (TID 2517)
19/06/20 10:24:54 INFO executor.Executor: Running task 221.1 in stage 1.0 (TID 2518)
19/06/20 10:24:54 INFO executor.Executor: Running task 625.0 in stage 1.0 (TID 2516)
19/06/20 10:24:54 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:24:54 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 2 ms
19/06/20 10:24:54 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:24:54 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 3 ms
19/06/20 10:24:54 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:24:54 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 2 ms
19/06/20 10:25:49 INFO collection.ExternalSorter: Thread 102 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:26:48 INFO collection.ExternalSorter: Thread 100 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:26:48 INFO collection.ExternalSorter: Thread 103 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:31:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:31:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:32:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:32:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:32:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:32:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:32:31 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000625_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000625
19/06/20 10:32:31 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000625_0: Committed
19/06/20 10:32:31 INFO executor.Executor: Finished task 625.0 in stage 1.0 (TID 2516). 1299 bytes result sent to driver
19/06/20 10:32:31 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2707
19/06/20 10:32:31 INFO executor.Executor: Running task 791.0 in stage 1.0 (TID 2707)
19/06/20 10:32:31 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:32:31 INFO storage.ShuffleBlockFetcherIterator: Started 11 remote fetches in 3 ms
19/06/20 10:32:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000430_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000430
19/06/20 10:32:58 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000430_0: Committed
19/06/20 10:32:58 INFO executor.Executor: Finished task 430.0 in stage 1.0 (TID 2305). 1299 bytes result sent to driver
19/06/20 10:32:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2723
19/06/20 10:32:58 INFO executor.Executor: Running task 805.0 in stage 1.0 (TID 2723)
19/06/20 10:32:58 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:32:58 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 2 ms
19/06/20 10:33:14 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000221_1' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000221
19/06/20 10:33:14 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000221_1: Committed
19/06/20 10:33:14 INFO executor.Executor: Finished task 221.1 in stage 1.0 (TID 2518). 1299 bytes result sent to driver
19/06/20 10:33:14 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2735
19/06/20 10:33:14 INFO executor.Executor: Running task 815.0 in stage 1.0 (TID 2735)
19/06/20 10:33:14 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:33:14 INFO storage.ShuffleBlockFetcherIterator: Started 8 remote fetches in 2 ms
19/06/20 10:33:28 INFO collection.ExternalSorter: Thread 103 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:34:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:34:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:34:28 INFO collection.ExternalSorter: Thread 102 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:34:43 INFO collection.ExternalSorter: Thread 101 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:35:34 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000321_1' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000321
19/06/20 10:35:34 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000321_1: Committed
19/06/20 10:35:34 INFO executor.Executor: Finished task 321.1 in stage 1.0 (TID 2517). 1299 bytes result sent to driver
19/06/20 10:35:34 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2888
19/06/20 10:35:34 INFO executor.Executor: Running task 955.0 in stage 1.0 (TID 2888)
19/06/20 10:35:34 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:35:34 INFO storage.ShuffleBlockFetcherIterator: Started 6 remote fetches in 18 ms
19/06/20 10:38:34 INFO collection.ExternalSorter: Thread 100 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:40:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:40:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:40:41 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:40:41 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:40:48 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000805_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000805
19/06/20 10:40:48 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000805_0: Committed
19/06/20 10:40:48 INFO executor.Executor: Finished task 805.0 in stage 1.0 (TID 2723). 1299 bytes result sent to driver
19/06/20 10:40:48 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3081
19/06/20 10:40:48 INFO executor.Executor: Running task 1128.0 in stage 1.0 (TID 3081)
19/06/20 10:40:48 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:40:48 INFO storage.ShuffleBlockFetcherIterator: Started 14 remote fetches in 16 ms
19/06/20 10:41:24 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000791_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000791
19/06/20 10:41:24 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000791_0: Committed
19/06/20 10:41:24 INFO executor.Executor: Finished task 791.0 in stage 1.0 (TID 2707). 1299 bytes result sent to driver
19/06/20 10:41:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3093
19/06/20 10:41:24 INFO executor.Executor: Running task 1137.0 in stage 1.0 (TID 3093)
19/06/20 10:41:24 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:41:24 INFO storage.ShuffleBlockFetcherIterator: Started 6 remote fetches in 733 ms
19/06/20 10:41:43 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:41:43 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:42:51 WARN hdfs.DFSClient: Slow ReadProcessor read fields took 49124ms (threshold=30000ms); ack: seqno: 6685 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK]]
19/06/20 10:42:52 INFO collection.ExternalSorter: Thread 101 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:43:14 INFO collection.ExternalSorter: Thread 103 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:43:36 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000815_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000815
19/06/20 10:43:36 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000815_0: Committed
19/06/20 10:43:36 INFO executor.Executor: Finished task 815.0 in stage 1.0 (TID 2735). 1299 bytes result sent to driver
19/06/20 10:43:36 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3140
19/06/20 10:43:36 INFO executor.Executor: Running task 1183.0 in stage 1.0 (TID 3140)
19/06/20 10:43:36 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:43:36 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 40 ms
19/06/20 10:43:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:43:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:44:41 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_000955_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_000955
19/06/20 10:44:41 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_000955_0: Committed
19/06/20 10:44:41 INFO executor.Executor: Finished task 955.0 in stage 1.0 (TID 2888). 1299 bytes result sent to driver
19/06/20 10:44:41 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3172
19/06/20 10:44:41 INFO executor.Executor: Running task 1002.1 in stage 1.0 (TID 3172)
19/06/20 10:44:41 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:44:41 INFO storage.ShuffleBlockFetcherIterator: Started 9 remote fetches in 5 ms
19/06/20 10:46:19 INFO collection.ExternalSorter: Thread 102 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:47:22 INFO collection.ExternalSorter: Thread 100 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:49:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:49:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:51:03 WARN hdfs.DFSClient: Slow ReadProcessor read fields took 56428ms (threshold=30000ms); ack: seqno: 11660 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK]]
19/06/20 10:51:16 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001137_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001137
19/06/20 10:51:16 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001137_0: Committed
19/06/20 10:51:16 INFO executor.Executor: Finished task 1137.0 in stage 1.0 (TID 3093). 1299 bytes result sent to driver
19/06/20 10:51:16 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3476
19/06/20 10:51:16 INFO executor.Executor: Running task 1160.1 in stage 1.0 (TID 3476)
19/06/20 10:51:16 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:51:16 INFO storage.ShuffleBlockFetcherIterator: Started 10 remote fetches in 2 ms
19/06/20 10:52:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:52:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:52:56 INFO collection.ExternalSorter: Thread 103 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:53:35 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001128_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001128
19/06/20 10:53:35 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001128_0: Committed
19/06/20 10:53:35 INFO executor.Executor: Finished task 1128.0 in stage 1.0 (TID 3081). 1299 bytes result sent to driver
19/06/20 10:53:35 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3532
19/06/20 10:53:35 INFO executor.Executor: Running task 1539.0 in stage 1.0 (TID 3532)
19/06/20 10:53:35 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:53:35 INFO storage.ShuffleBlockFetcherIterator: Started 11 remote fetches in 1 ms
19/06/20 10:56:15 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:56:15 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:58:37 WARN hdfs.DFSClient: Slow ReadProcessor read fields took 139292ms (threshold=30000ms); ack: seqno: 2086 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK]]
19/06/20 10:58:37 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-77535376-10.1.1.4-1561010540702:blk_1073747331_6507
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:734)
19/06/20 10:58:37 ERROR util.Utils: Aborting task
java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:58:37 ERROR io.SparkHadoopWriter: Task attempt_20190620092633_0001_r_001002_1 aborted.
19/06/20 10:58:37 ERROR executor.Executor: Exception in task 1002.1 in stage 1.0 (TID 3172)
org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:155)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83)
	at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: All datanodes DatanodeInfoWithStorage[10.1.1.4:50010,DS-7e2562ab-d0d7-4364-ad17-77b7c8865721,DISK] are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
19/06/20 10:58:37 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3764
19/06/20 10:58:37 INFO executor.Executor: Running task 1758.0 in stage 1.0 (TID 3764)
19/06/20 10:58:37 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:58:37 INFO storage.ShuffleBlockFetcherIterator: Started 13 remote fetches in 2 ms
19/06/20 10:58:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:58:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 10:58:37 INFO collection.ExternalSorter: Thread 101 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 10:59:30 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001183_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001183
19/06/20 10:59:30 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001183_0: Committed
19/06/20 10:59:30 INFO executor.Executor: Finished task 1183.0 in stage 1.0 (TID 3140). 1299 bytes result sent to driver
19/06/20 10:59:30 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3791
19/06/20 10:59:30 INFO executor.Executor: Running task 1783.0 in stage 1.0 (TID 3791)
19/06/20 10:59:30 INFO storage.ShuffleBlockFetcherIterator: Getting 1875 non-empty blocks including 14 local blocks and 1861 remote blocks
19/06/20 10:59:30 INFO storage.ShuffleBlockFetcherIterator: Started 13 remote fetches in 2 ms
19/06/20 11:00:19 INFO collection.ExternalSorter: Thread 100 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 11:01:03 INFO collection.ExternalSorter: Thread 102 spilling in-memory map of 1070.1 MB to disk (1 time so far)
19/06/20 11:03:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:03:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:14 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001160_1' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001160
19/06/20 11:04:14 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001160_1: Committed
19/06/20 11:04:14 INFO executor.Executor: Finished task 1160.1 in stage 1.0 (TID 3476). 1299 bytes result sent to driver
19/06/20 11:04:22 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:22 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:46 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001539_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001539
19/06/20 11:04:46 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001539_0: Committed
19/06/20 11:04:46 INFO executor.Executor: Finished task 1539.0 in stage 1.0 (TID 3532). 1299 bytes result sent to driver
19/06/20 11:04:55 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001758_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001758
19/06/20 11:04:55 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001758_0: Committed
19/06/20 11:04:55 INFO executor.Executor: Finished task 1758.0 in stage 1.0 (TID 3764). 1299 bytes result sent to driver
19/06/20 11:04:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:04:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 11:05:10 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620092633_0001_r_001783_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-output/_temporary/0/task_20190620092633_0001_r_001783
19/06/20 11:05:10 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620092633_0001_r_001783_0: Committed
19/06/20 11:05:10 INFO executor.Executor: Finished task 1783.0 in stage 1.0 (TID 3791). 1299 bytes result sent to driver
19/06/20 11:08:45 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/06/20 11:08:45 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
