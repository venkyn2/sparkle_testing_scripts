Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Spark Command: /opt/jdk1.8.0_131/jre/bin/java -cp /var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8153 spark://mdc-ch1-cust4:7077 -h mdc-ch1-cust4
========================================
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/19 03:40:43 INFO Worker: Started daemon with process name: 727799@mdc-ch1-cust4
19/06/19 03:40:43 INFO SignalUtils: Registered signal handler for TERM
19/06/19 03:40:43 INFO SignalUtils: Registered signal handler for HUP
19/06/19 03:40:43 INFO SignalUtils: Registered signal handler for INT
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 03:40:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/19 03:40:43 INFO SecurityManager: Changing view acls to: root
19/06/19 03:40:43 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:40:43 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:40:43 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:40:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 03:40:44 INFO Utils: Successfully started service 'sparkWorker' on port 34675.
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 03:40:44 INFO Worker: Starting Spark worker mdc-ch1-cust4:34675 with 576 cores, 22.9 TB RAM
19/06/19 03:40:44 INFO Worker: Running Spark version 2.4.0
19/06/19 03:40:44 INFO Worker: Spark home: /var/tmp/spark2.0hpcplatform/multicore/worker36
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
Java HotSpot(TM) 64-Bit Server VM warning: sched_getaffinity failed (Invalid argument)- using online processor count (576) which may exceed available processors
19/06/19 03:40:44 INFO Utils: Successfully started service 'WorkerUI' on port 8153.
19/06/19 03:40:44 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://mdc-ch1-cust4.mdc.ext.hpe.com:8153
19/06/19 03:40:44 INFO Worker: Connecting to master mdc-ch1-cust4:7077...
19/06/19 03:40:44 INFO TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:7077 after 24 ms (0 ms spent in bootstraps)
19/06/19 03:40:44 INFO Worker: Successfully registered with master spark://mdc-ch1-cust4.mdc.ext.hpe.com:7077
19/06/19 03:42:26 INFO Worker: Asked to launch executor app-20190619034226-0000/6 for TeraSort
19/06/19 03:42:27 INFO SecurityManager: Changing view acls to: root
19/06/19 03:42:27 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:42:27 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:42:27 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:42:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:42:27 INFO Worker: Asked to launch executor app-20190619034226-0000/7 for TeraSort
19/06/19 03:42:27 INFO Worker: Asked to launch executor app-20190619034226-0000/8 for TeraSort
19/06/19 03:42:27 INFO SecurityManager: Changing view acls to: root
19/06/19 03:42:27 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:42:27 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:42:27 INFO SecurityManager: Changing view acls to: root
19/06/19 03:42:27 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:42:27 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:42:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:42:27 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:42:27 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:42:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:42:27 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39423" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39423" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619034226-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 03:42:27 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39423" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39423" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619034226-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 03:42:27 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39423" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39423" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619034226-0000" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 03:49:26 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker36/work/app-20190619034226-0000/6/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 03:49:26 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker36/work/app-20190619034226-0000/7/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 03:49:26 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker36/work/app-20190619034226-0000/8/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 03:50:35 INFO Worker: Asked to kill executor app-20190619034226-0000/8
19/06/19 03:50:35 INFO ExecutorRunner: Runner thread for executor app-20190619034226-0000/8 interrupted
19/06/19 03:50:35 INFO ExecutorRunner: Killing process!
19/06/19 03:50:35 INFO Worker: Asked to kill executor app-20190619034226-0000/7
19/06/19 03:50:35 INFO ExecutorRunner: Runner thread for executor app-20190619034226-0000/7 interrupted
19/06/19 03:50:35 INFO ExecutorRunner: Killing process!
19/06/19 03:50:35 INFO Worker: Asked to kill executor app-20190619034226-0000/6
19/06/19 03:50:35 INFO ExecutorRunner: Runner thread for executor app-20190619034226-0000/6 interrupted
19/06/19 03:50:35 INFO ExecutorRunner: Killing process!
19/06/19 03:50:37 INFO Worker: Executor app-20190619034226-0000/6 finished with state KILLED exitStatus 143
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619034226-0000, execId=6)
19/06/19 03:50:37 INFO Worker: Executor app-20190619034226-0000/7 finished with state KILLED exitStatus 143
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619034226-0000, execId=7)
19/06/19 03:50:37 INFO Worker: Executor app-20190619034226-0000/8 finished with state KILLED exitStatus 143
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619034226-0000, execId=8)
19/06/19 03:50:37 INFO ExternalShuffleBlockResolver: Application app-20190619034226-0000 removed, cleanupLocalDirs = true
19/06/19 03:50:37 INFO Worker: Cleaning up local directories for application app-20190619034226-0000
19/06/19 03:54:52 INFO Worker: Asked to launch executor app-20190619035452-0001/6 for TeraSort
19/06/19 03:54:52 INFO SecurityManager: Changing view acls to: root
19/06/19 03:54:52 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:54:52 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:54:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:54:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:54:52 INFO Worker: Asked to launch executor app-20190619035452-0001/7 for TeraSort
19/06/19 03:54:52 INFO SecurityManager: Changing view acls to: root
19/06/19 03:54:52 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:54:52 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:54:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:54:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:54:52 INFO Worker: Asked to launch executor app-20190619035452-0001/8 for TeraSort
19/06/19 03:54:52 INFO SecurityManager: Changing view acls to: root
19/06/19 03:54:52 INFO SecurityManager: Changing modify acls to: root
19/06/19 03:54:52 INFO SecurityManager: Changing view acls groups to: 
19/06/19 03:54:52 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 03:54:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 03:54:53 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=46783" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:46783" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619035452-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 03:54:53 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=46783" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:46783" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619035452-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 03:54:53 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=46783" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:46783" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619035452-0001" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:01:30 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker36/work/app-20190619035452-0001/8/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppender.appendToFile(FileAppender.scala:92)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply$mcV$sp(FileAppender.scala:75)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1.apply(FileAppender.scala:62)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:78)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
19/06/19 04:01:30 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker36/work/app-20190619035452-0001/6/stderr
java.io.IOException: No spac19/06/19 04:03:00 INFO Worker: Asked to kill executor app-20190619035452-0001/8
19/06/19 04:03:00 INFO Worker: Asked to kill executor app-20190619035452-0001/7
19/06/19 04:03:00 INFO ExecutorRunner: Runner thread for executor app-20190619035452-0001/8 interrupted
19/06/19 04:03:00 INFO ExecutorRunner: Killing process!
19/06/19 04:03:00 INFO ExecutorRunner: Runner thread for executor app-20190619035452-0001/7 interrupted
19/06/19 04:03:00 INFO ExecutorRunner: Killing process!
19/06/19 04:03:00 INFO Worker: Asked to kill executor app-20190619035452-0001/6
19/06/19 04:03:00 INFO ExecutorRunner: Runner thread for executor app-20190619035452-0001/6 interrupted
19/06/19 04:03:00 INFO ExecutorRunner: Killing process!
19/06/19 04:03:03 INFO Worker: Executor app-20190619035452-0001/8 finished with state KILLED exitStatus 143
19/06/19 04:03:03 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 04:03:03 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619035452-0001, execId=8)
19/06/19 04:03:04 INFO Worker: Executor app-20190619035452-0001/7 finished with state KILLED exitStatus 143
19/06/19 04:03:04 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 04:03:04 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619035452-0001, execId=7)
19/06/19 04:03:06 INFO Worker: Executor app-20190619035452-0001/6 finished with state KILLED exitStatus 143
19/06/19 04:03:06 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 04:03:06 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619035452-0001, execId=6)
19/06/19 04:03:06 INFO ExternalShuffleBlockResolver: Application app-20190619035452-0001 removed, cleanupLocalDirs = true
19/06/19 04:03:06 INFO Worker: Cleaning up local directories for application app-20190619035452-0001
19/06/19 04:23:58 INFO Worker: Asked to launch executor app-20190619042358-0002/6 for TeraValidate
19/06/19 04:23:58 INFO Worker: Asked to launch executor app-20190619042358-0002/7 for TeraValidate
19/06/19 04:23:58 INFO SecurityManager: Changing view acls to: root
19/06/19 04:23:58 INFO SecurityManager: Changing modify acls to: root
19/06/19 04:23:58 INFO SecurityManager: Changing view acls groups to: 
19/06/19 04:23:58 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 04:23:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 04:23:58 INFO SecurityManager: Changing view acls to: root
19/06/19 04:23:58 INFO SecurityManager: Changing modify acls to: root
19/06/19 04:23:58 INFO SecurityManager: Changing view acls groups to: 
19/06/19 04:23:58 INFO Worker: Asked to launch executor app-20190619042358-0002/8 for TeraValidate
19/06/19 04:23:58 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 04:23:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 04:23:58 INFO SecurityManager: Changing view acls to: root
19/06/19 04:23:58 INFO SecurityManager: Changing modify acls to: root
19/06/19 04:23:58 INFO SecurityManager: Changing view acls groups to: 
19/06/19 04:23:58 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 04:23:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 04:23:58 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=33689" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:33689" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619042358-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:23:58 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=33689" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:33689" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619042358-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:23:58 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx5120M" "-Dspark.driver.port=33689" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:33689" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619042358-0002" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:32:15 INFO Worker: Asked to kill executor app-20190619042358-0002/8
19/06/19 04:32:15 INFO ExecutorRunner: Runner thread for executor app-20190619042358-0002/8 interrupted
19/06/19 04:32:15 INFO ExecutorRunner: Killing process!
19/06/19 04:32:15 INFO Worker: Asked to kill executor app-20190619042358-0002/7
19/06/19 04:32:15 INFO ExecutorRunner: Runner thread for executor app-20190619042358-0002/7 interrupted
19/06/19 04:32:15 INFO ExecutorRunner: Killing process!
19/06/19 04:32:15 INFO Worker: Asked to kill executor app-20190619042358-0002/6
19/06/19 04:32:15 INFO ExecutorRunner: Runner thread for executor app-20190619042358-0002/6 interrupted
19/06/19 04:32:15 INFO ExecutorRunner: Killing process!
19/06/19 04:32:17 INFO Worker: Executor app-20190619042358-0002/8 finished with state KILLED exitStatus 143
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619042358-0002, execId=8)
19/06/19 04:32:17 INFO Worker: Executor app-20190619042358-0002/6 finished with state KILLED exitStatus 143
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619042358-0002, execId=6)
19/06/19 04:32:17 INFO Worker: Executor app-20190619042358-0002/7 finished with state KILLED exitStatus 143
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619042358-0002, execId=7)
19/06/19 04:32:17 INFO ExternalShuffleBlockResolver: Application app-20190619042358-0002 removed, cleanupLocalDirs = true
19/06/19 04:32:17 INFO Worker: Cleaning up local directories for application app-20190619042358-0002
19/06/19 04:46:23 INFO Worker: Asked to launch executor app-20190619044623-0003/6 for TeraSort
19/06/19 04:46:23 INFO Worker: Asked to launch executor app-20190619044623-0003/7 for TeraSort
19/06/19 04:46:23 INFO SecurityManager: Changing view acls to: root
19/06/19 04:46:23 INFO SecurityManager: Changing modify acls to: root
19/06/19 04:46:23 INFO SecurityManager: Changing view acls groups to: 
19/06/19 04:46:23 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 04:46:23 INFO SecurityManager: Changing view acls to: root
19/06/19 04:46:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 04:46:23 INFO SecurityManager: Changing modify acls to: root
19/06/19 04:46:23 INFO SecurityManager: Changing view acls groups to: 
19/06/19 04:46:23 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 04:46:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 04:46:23 INFO Worker: Asked to launch executor app-20190619044623-0003/8 for TeraSort
19/06/19 04:46:23 INFO SecurityManager: Changing view acls to: root
19/06/19 04:46:23 INFO SecurityManager: Changing modify acls to: root
19/06/19 04:46:23 INFO SecurityManager: Changing view acls groups to: 
19/06/19 04:46:23 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 04:46:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 04:46:23 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=40973" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:40973" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619044623-0003" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:46:23 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=40973" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:40973" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619044623-0003" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:46:23 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=40973" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:40973" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619044623-0003" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 04:51:09 ERROR FileAppender: Error writing stream to file /var/tmp/spark2.0hpcplatform/multicore/worker36/work/app-20190619044623-0003/7/stderr
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.logging.FileAppen19/06/19 04:54:41 INFO Worker: Asked to kill executor app-20190619044623-0003/8
19/06/19 04:54:41 INFO Worker: Asked to kill executor app-20190619044623-0003/7
19/06/19 04:54:41 INFO ExecutorRunner: Runner thread for executor app-20190619044623-0003/8 interrupted
19/06/19 04:54:41 INFO ExecutorRunner: Killing process!
19/06/19 04:54:41 INFO ExecutorRunner: Runner thread for executor app-20190619044623-0003/7 interrupted
19/06/19 04:54:41 INFO ExecutorRunner: Killing process!
19/06/19 04:54:41 INFO Worker: Asked to kill executor app-20190619044623-0003/6
19/06/19 04:54:41 INFO ExecutorRunner: Runner thread for executor app-20190619044623-0003/6 interrupted
19/06/19 04:54:41 INFO ExecutorRunner: Killing process!
19/06/19 04:54:45 INFO Worker: Executor app-20190619044623-0003/7 finished with state KILLED exitStatus 143
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619044623-0003, execId=7)
19/06/19 04:54:45 INFO Worker: Executor app-20190619044623-0003/6 finished with state KILLED exitStatus 143
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619044623-0003, execId=6)
19/06/19 04:54:45 INFO Worker: Executor app-20190619044623-0003/8 finished with state KILLED exitStatus 143
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619044623-0003, execId=8)
19/06/19 04:54:45 INFO ExternalShuffleBlockResolver: Application app-20190619044623-0003 removed, cleanupLocalDirs = true
19/06/19 04:54:45 INFO Worker: Cleaning up local directories for application app-20190619044623-0003
19/06/19 05:03:00 INFO Worker: Asked to launch executor app-20190619050300-0004/6 for TeraSort
19/06/19 05:03:00 INFO Worker: Asked to launch executor app-20190619050300-0004/7 for TeraSort
19/06/19 05:03:00 INFO SecurityManager: Changing view acls to: root
19/06/19 05:03:00 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:03:00 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:03:00 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:03:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:03:00 INFO Worker: Asked to launch executor app-20190619050300-0004/8 for TeraSort
19/06/19 05:03:00 INFO SecurityManager: Changing view acls to: root
19/06/19 05:03:00 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:03:00 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:03:00 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:03:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:03:00 INFO SecurityManager: Changing view acls to: root
19/06/19 05:03:00 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:03:00 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:03:00 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:03:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:03:00 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=35505" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35505" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619050300-0004" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:03:00 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=35505" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35505" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619050300-0004" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:03:00 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=35505" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:35505" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619050300-0004" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:08:57 INFO Worker: Asked to kill executor app-20190619050300-0004/8
19/06/19 05:08:57 INFO Worker: Asked to kill executor app-20190619050300-0004/7
19/06/19 05:08:57 INFO ExecutorRunner: Runner thread for executor app-20190619050300-0004/8 interrupted
19/06/19 05:08:57 INFO ExecutorRunner: Runner thread for executor app-20190619050300-0004/7 interrupted
19/06/19 05:08:57 INFO Worker: Asked to kill executor app-20190619050300-0004/6
19/06/19 05:08:57 INFO ExecutorRunner: Killing process!
19/06/19 05:08:57 INFO ExecutorRunner: Killing process!
19/06/19 05:08:57 INFO ExecutorRunner: Runner thread for executor app-20190619050300-0004/6 interrupted
19/06/19 05:08:57 INFO ExecutorRunner: Killing process!
19/06/19 05:09:00 INFO Worker: Executor app-20190619050300-0004/8 finished with state KILLED exitStatus 143
19/06/19 05:09:00 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 05:09:00 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619050300-0004, execId=8)
19/06/19 05:09:00 INFO Worker: Executor app-20190619050300-0004/7 finished with state KILLED exitStatus 143
19/06/19 05:09:00 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 05:09:00 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619050300-0004, execId=7)
19/06/19 05:09:01 INFO Worker: Executor app-20190619050300-0004/6 finished with state KILLED exitStatus 143
19/06/19 05:09:01 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 05:09:01 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619050300-0004, execId=6)
19/06/19 05:09:01 INFO ExternalShuffleBlockResolver: Application app-20190619050300-0004 removed, cleanupLocalDirs = true
19/06/19 05:09:01 INFO Worker: Cleaning up local directories for application app-20190619050300-0004
19/06/19 05:09:17 INFO Worker: Asked to launch executor app-20190619050917-0005/6 for TeraSort
19/06/19 05:09:17 INFO Worker: Asked to launch executor app-20190619050917-0005/7 for TeraSort
19/06/19 05:09:17 INFO SecurityManager: Changing view acls to: root
19/06/19 05:09:17 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:09:17 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:09:17 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:09:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:09:17 INFO SecurityManager: Changing view acls to: root
19/06/19 05:09:17 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:09:17 INFO Worker: Asked to launch executor app-20190619050917-0005/8 for TeraSort
19/06/19 05:09:17 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:09:17 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:09:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:09:17 INFO SecurityManager: Changing view acls to: root
19/06/19 05:09:17 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:09:17 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:09:17 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:09:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:09:17 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39675" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39675" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619050917-0005" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:09:17 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39675" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39675" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619050917-0005" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:09:17 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=39675" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39675" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619050917-0005" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:11:29 INFO Worker: Asked to kill executor app-20190619050917-0005/8
19/06/19 05:11:29 INFO Worker: Asked to kill executor app-20190619050917-0005/7
19/06/19 05:11:29 INFO Worker: Asked to kill executor app-20190619050917-0005/6
19/06/19 05:11:29 INFO ExecutorRunner: Runner thread for executor app-20190619050917-0005/6 interrupted
19/06/19 05:11:29 INFO ExecutorRunner: Runner thread for executor app-20190619050917-0005/7 interrupted
19/06/19 05:11:29 INFO ExecutorRunner: Killing process!
19/06/19 05:11:29 INFO ExecutorRunner: Runner thread for executor app-20190619050917-0005/8 interrupted
19/06/19 05:11:29 INFO ExecutorRunner: Killing process!
19/06/19 05:11:29 INFO ExecutorRunner: Killing process!
19/06/19 05:11:33 INFO Worker: Executor app-20190619050917-0005/8 finished with state KILLED exitStatus 143
19/06/19 05:11:33 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 05:11:33 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619050917-0005, execId=8)
19/06/19 05:11:33 INFO Worker: Executor app-20190619050917-0005/6 finished with state KILLED exitStatus 143
19/06/19 05:11:33 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 05:11:33 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619050917-0005, execId=6)
19/06/19 05:11:34 INFO Worker: Executor app-20190619050917-0005/7 finished with state KILLED exitStatus 143
19/06/19 05:11:34 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 05:11:34 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619050917-0005, execId=7)
19/06/19 05:11:34 INFO ExternalShuffleBlockResolver: Application app-20190619050917-0005 removed, cleanupLocalDirs = true
19/06/19 05:11:34 INFO Worker: Cleaning up local directories for application app-20190619050917-0005
19/06/19 05:18:03 INFO Worker: Asked to launch executor app-20190619051803-0006/6 for TeraSort
19/06/19 05:18:03 INFO Worker: Asked to launch executor app-20190619051803-0006/7 for TeraSort
19/06/19 05:18:03 INFO Worker: Asked to launch executor app-20190619051803-0006/8 for TeraSort
19/06/19 05:18:03 INFO SecurityManager: Changing view acls to: root
19/06/19 05:18:03 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:18:03 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:18:03 INFO SecurityManager: Changing view acls to: root
19/06/19 05:18:03 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:18:03 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:18:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:18:03 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:18:03 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:18:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:18:03 INFO SecurityManager: Changing view acls to: root
19/06/19 05:18:03 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:18:03 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:18:03 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:18:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:18:03 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-Dspark.driver.port=39015" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39015" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619051803-0006" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:18:03 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-Dspark.driver.port=39015" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39015" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619051803-0006" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:18:03 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-Dspark.driver.port=39015" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:39015" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619051803-0006" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:18:38 INFO Worker: Asked to kill executor app-20190619051803-0006/8
19/06/19 05:18:38 INFO Worker: Asked to kill executor app-20190619051803-0006/7
19/06/19 05:18:38 INFO ExecutorRunner: Runner thread for executor app-20190619051803-0006/8 interrupted
19/06/19 05:18:38 INFO ExecutorRunner: Killing process!
19/06/19 05:18:38 INFO ExecutorRunner: Runner thread for executor app-20190619051803-0006/7 interrupted
19/06/19 05:18:38 INFO ExecutorRunner: Killing process!
19/06/19 05:18:38 INFO Worker: Asked to kill executor app-20190619051803-0006/6
19/06/19 05:18:38 INFO ExecutorRunner: Runner thread for executor app-20190619051803-0006/6 interrupted
19/06/19 05:18:38 INFO ExecutorRunner: Killing process!
19/06/19 05:18:40 INFO Worker: Executor app-20190619051803-0006/6 finished with state KILLED exitStatus 143
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619051803-0006, execId=6)
19/06/19 05:18:40 INFO Worker: Executor app-20190619051803-0006/8 finished with state KILLED exitStatus 143
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619051803-0006, execId=8)
19/06/19 05:18:40 INFO Worker: Executor app-20190619051803-0006/7 finished with state KILLED exitStatus 143
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619051803-0006, execId=7)
19/06/19 05:18:40 INFO ExternalShuffleBlockResolver: Application app-20190619051803-0006 removed, cleanupLocalDirs = true
19/06/19 05:18:40 INFO Worker: Cleaning up local directories for application app-20190619051803-0006
19/06/19 05:23:46 INFO Worker: Asked to launch executor app-20190619052346-0007/6 for TeraSort
19/06/19 05:23:46 INFO Worker: Asked to launch executor app-20190619052346-0007/7 for TeraSort
19/06/19 05:23:46 INFO SecurityManager: Changing view acls to: root
19/06/19 05:23:46 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:23:46 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:23:46 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:23:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:23:46 INFO Worker: Asked to launch executor app-20190619052346-0007/8 for TeraSort
19/06/19 05:23:46 INFO SecurityManager: Changing view acls to: root
19/06/19 05:23:46 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:23:46 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:23:46 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:23:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:23:46 INFO SecurityManager: Changing view acls to: root
19/06/19 05:23:46 INFO SecurityManager: Changing modify acls to: root
19/06/19 05:23:46 INFO SecurityManager: Changing view acls groups to: 
19/06/19 05:23:46 INFO SecurityManager: Changing modify acls groups to: 
19/06/19 05:23:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/19 05:23:46 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=45235" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45235" "--executor-id" "7" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619052346-0007" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:23:46 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=45235" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45235" "--executor-id" "6" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619052346-0007" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:23:46 INFO ExecutorRunner: Launch command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker36/conf:/var/tmp/spark2.0hpcplatform/multicore/worker36/assembly/target/scala-2.11/jars/*" "-Xmx8192M" "-Dspark.driver.port=45235" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:45235" "--executor-id" "8" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190619052346-0007" "--worker-url" "spark://Worker@mdc-ch1-cust4:34675"
19/06/19 05:25:16 INFO Worker: Asked to kill executor app-20190619052346-0007/8
19/06/19 05:25:16 INFO Worker: Asked to kill executor app-20190619052346-0007/7
19/06/19 05:25:16 INFO ExecutorRunner: Runner thread for executor app-20190619052346-0007/8 interrupted
19/06/19 05:25:16 INFO ExecutorRunner: Killing process!
19/06/19 05:25:16 INFO ExecutorRunner: Runner thread for executor app-20190619052346-0007/7 interrupted
19/06/19 05:25:16 INFO Worker: Asked to kill executor app-20190619052346-0007/6
19/06/19 05:25:16 INFO ExecutorRunner: Runner thread for executor app-20190619052346-0007/6 interrupted
19/06/19 05:25:16 INFO ExecutorRunner: Killing process!
19/06/19 05:25:16 INFO ExecutorRunner: Killing process!
19/06/19 05:25:19 INFO Worker: Executor app-20190619052346-0007/8 finished with state KILLED exitStatus 143
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 8
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619052346-0007, execId=8)
19/06/19 05:25:19 INFO Worker: Executor app-20190619052346-0007/6 finished with state KILLED exitStatus 143
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619052346-0007, execId=6)
19/06/19 05:25:19 INFO Worker: Executor app-20190619052346-0007/7 finished with state KILLED exitStatus 143
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 7
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20190619052346-0007, execId=7)
19/06/19 05:25:19 INFO ExternalShuffleBlockResolver: Application app-20190619052346-0007 removed, cleanupLocalDirs = true
19/06/19 05:25:19 INFO Worker: Cleaning up local directories for application app-20190619052346-0007
19/06/19 05:27:47 INFO Worker: mdc-ch1-cust4:7077 Disassociated !
19/06/19 05:27:47 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
19/06/19 05:27:47 INFO Worker: mdc-ch1-cust4.mdc.ext.hpe.com:7077 Disassociated !
19/06/19 05:27:47 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
19/06/19 05:27:47 INFO Worker: Connecting to master mdc-ch1-cust4:7077...
19/06/19 05:27:47 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
19/06/19 05:27:47 INFO TransportClientFactory: Found inactive connection to mdc-ch1-cust4/10.1.1.4:7077, creating a new one.
19/06/19 05:27:47 WARN Worker: Failed to connect to master mdc-ch1-cust4:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1$$anon$1.run(Worker.scala:253)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:27:54 INFO Worker: Retrying connection to master (attempt # 1)
19/06/19 05:27:54 INFO Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 05:27:54 WARN Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:28:01 INFO Worker: Retrying connection to master (attempt # 2)
19/06/19 05:28:01 INFO Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 05:28:01 WARN Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:28:08 INFO Worker: Retrying connection to master (attempt # 3)
19/06/19 05:28:08 INFO Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 05:28:09 WARN Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:28:15 INFO Worker: Retrying connection to master (attempt # 4)
19/06/19 05:28:15 INFO Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 05:28:16 WARN Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:28:22 INFO Worker: Retrying connection to master (attempt # 5)
19/06/19 05:28:22 INFO Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 05:28:22 WARN Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:28:29 INFO Worker: Retrying connection to master (attempt # 6)
19/06/19 05:28:29 INFO Worker: Connecting to master mdc-ch1-cust4.mdc.ext.hpe.com:7077...
19/06/19 05:28:29 WARN Worker: Failed to connect to master mdc-ch1-cust4.mdc.ext.hpe.com:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2.run(Worker.scala:310)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/06/19 05:28:45 ERROR Worker: RECEIVED SIGNAL TERM
19/06/19 05:28:45 INFO ShutdownHookManager: Shutdown hook called
19/06/19 05:28:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-b68ab425-8efe-4c03-a613-a237e01c2b29
