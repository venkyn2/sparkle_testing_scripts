Spark Executor Command: "/opt/jdk1.8.0_131/jre/bin/java" "-cp" "/var/tmp/spark2.0hpcplatform/lib/firesteel-2.4.0.jar:/var/tmp/spark2.0hpcplatform/multicore/worker5/conf/:/var/tmp/spark2.0hpcplatform/multicore/worker5/assembly/target/scala-2.11/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx8192M" "-Dspark.driver.port=41135" "-Dspark.rpc.netty.dispatcher.numThreads=10" "-XX:-UseBiasedLocking" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:41135" "--executor-id" "67" "--hostname" "mdc-ch1-cust4" "--cores" "4" "--app-id" "app-20190620085825-0010" "--worker-url" "spark://Worker@mdc-ch1-cust4:43473"
========================================

19/06/20 08:58:25 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 82835@mdc-ch1-cust4
19/06/20 08:58:25 INFO util.SignalUtils: Registered signal handler for TERM
19/06/20 08:58:25 INFO util.SignalUtils: Registered signal handler for HUP
19/06/20 08:58:25 INFO util.SignalUtils: Registered signal handler for INT
19/06/20 08:58:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/20 08:58:25 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/06/20 08:58:25 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/06/20 08:58:25 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/20 08:58:25 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/20 08:58:25 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/20 08:58:26 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:41135 after 48 ms (0 ms spent in bootstraps)
19/06/20 08:58:26 WARN spark.SparkConf: The configuration key 'spark.kryoserializer.buffer.max.mb' has been deprecated as of Spark 1.4 and may be removed in the future. Please use the new key 'spark.kryoserializer.buffer.max' instead.
19/06/20 08:58:26 INFO spark.SecurityManager: Changing view acls to: root,nnnnnven
19/06/20 08:58:26 INFO spark.SecurityManager: Changing modify acls to: root,nnnnnven
19/06/20 08:58:26 INFO spark.SecurityManager: Changing view acls groups to: 
19/06/20 08:58:26 INFO spark.SecurityManager: Changing modify acls groups to: 
19/06/20 08:58:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, nnnnnven); groups with view permissions: Set(); users  with modify permissions: Set(root, nnnnnven); groups with modify permissions: Set()
19/06/20 08:58:26 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:41135 after 1 ms (0 ms spent in bootstraps)
19/06/20 08:58:26 INFO storage.DiskBlockManager: Created local directory at /data/spark-3744df16-8871-4013-a927-64801d6a246b/executor-4e1e7119-4804-44d7-ab57-195849da4e2e/blockmgr-c6fb1421-6795-4604-a182-4a74255e04e6
19/06/20 08:58:26 INFO memory.MemoryStore: MemoryStore started with capacity 4.1 GB
19/06/20 08:58:26 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@mdc-ch1-cust4.mdc.ext.hpe.com:41135
19/06/20 08:58:26 INFO worker.WorkerWatcher: Connecting to worker spark://Worker@mdc-ch1-cust4:43473
19/06/20 08:58:26 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4/10.1.1.4:43473 after 0 ms (0 ms spent in bootstraps)
19/06/20 08:58:26 INFO worker.WorkerWatcher: Successfully connected to spark://Worker@mdc-ch1-cust4:43473
19/06/20 08:58:26 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
19/06/20 08:58:26 INFO executor.Executor: Starting executor ID 67 on host mdc-ch1-cust4
19/06/20 08:58:26 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41015.
19/06/20 08:58:26 INFO netty.NettyBlockTransferService: Server created on mdc-ch1-cust4:41015
19/06/20 08:58:26 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/20 08:58:26 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(67, mdc-ch1-cust4, 41015, None)
19/06/20 08:58:26 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(67, mdc-ch1-cust4, 41015, None)
19/06/20 08:58:26 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(67, mdc-ch1-cust4, 41015, None)
19/06/20 08:58:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
19/06/20 08:58:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
19/06/20 08:58:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
19/06/20 08:58:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
19/06/20 08:58:26 INFO executor.Executor: Running task 11.0 in stage 0.0 (TID 11)
19/06/20 08:58:26 INFO executor.Executor: Running task 9.0 in stage 0.0 (TID 9)
19/06/20 08:58:26 INFO executor.Executor: Running task 10.0 in stage 0.0 (TID 10)
19/06/20 08:58:26 INFO executor.Executor: Running task 8.0 in stage 0.0 (TID 8)
19/06/20 08:58:26 INFO executor.Executor: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:41135/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1561046305169
19/06/20 08:58:26 INFO client.TransportClientFactory: Successfully created connection to mdc-ch1-cust4.mdc.ext.hpe.com/10.1.1.4:41135 after 2 ms (0 ms spent in bootstraps)
19/06/20 08:58:26 INFO util.Utils: Fetching spark://mdc-ch1-cust4.mdc.ext.hpe.com:41135/jars/spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to /data/spark-3744df16-8871-4013-a927-64801d6a246b/executor-4e1e7119-4804-44d7-ab57-195849da4e2e/spark-2197f9e7-dd62-4085-8bfd-f8b5db7b070c/fetchFileTemp6510066677428135063.tmp
19/06/20 08:58:26 INFO util.Utils: Copying /data/spark-3744df16-8871-4013-a927-64801d6a246b/executor-4e1e7119-4804-44d7-ab57-195849da4e2e/spark-2197f9e7-dd62-4085-8bfd-f8b5db7b070c/3765210891561046305169_cache to /var/tmp/spark2.0hpcplatform/multicore/worker5/work/app-20190620085825-0010/67/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar
19/06/20 08:58:27 INFO executor.Executor: Adding file:/var/tmp/spark2.0hpcplatform/multicore/worker5/work/app-20190620085825-0010/67/./spark-terasort-1.1-SNAPSHOT-jar-with-dependencies.jar to class loader
19/06/20 08:58:27 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
19/06/20 08:58:27 INFO client.TransportClientFactory: Successfully created connection to mdc-ch2-cust4/10.1.2.4:44515 after 1 ms (0 ms spent in bootstraps)
19/06/20 08:58:27 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.4 KB, free 4.1 GB)
19/06/20 08:58:27 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 111 ms
19/06/20 08:58:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 68.5 KB, free 4.1 GB)
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 08:58:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/06/20 09:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620085825_0001_r_000009_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/_temporary/0/task_20190620085825_0001_r_000009
19/06/20 09:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620085825_0001_r_000009_0: Committed
19/06/20 09:10:58 INFO executor.Executor: Finished task 9.0 in stage 0.0 (TID 9). 912 bytes result sent to driver
19/06/20 09:11:01 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620085825_0001_r_000010_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/_temporary/0/task_20190620085825_0001_r_000010
19/06/20 09:11:01 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620085825_0001_r_000010_0: Committed
19/06/20 09:11:01 INFO executor.Executor: Finished task 10.0 in stage 0.0 (TID 10). 869 bytes result sent to driver
19/06/20 09:11:06 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620085825_0001_r_000011_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/_temporary/0/task_20190620085825_0001_r_000011
19/06/20 09:11:06 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620085825_0001_r_000011_0: Committed
19/06/20 09:11:06 INFO executor.Executor: Finished task 11.0 in stage 0.0 (TID 11). 869 bytes result sent to driver
19/06/20 09:11:19 INFO hdfs.DFSClient: Could not complete /user/nnnnnven2000G/HSsort-input/_temporary/0/_temporary/attempt_20190620085825_0001_r_000008_0/part-r-00008 retrying...
19/06/20 09:11:19 INFO output.FileOutputCommitter: Saved output of task 'attempt_20190620085825_0001_r_000008_0' to hdfs://mdc-ch1-cust4:9000/user/nnnnnven2000G/HSsort-input/_temporary/0/task_20190620085825_0001_r_000008
19/06/20 09:11:19 INFO mapred.SparkHadoopMapRedUtil: attempt_20190620085825_0001_r_000008_0: Committed
19/06/20 09:11:19 INFO executor.Executor: Finished task 8.0 in stage 0.0 (TID 8). 869 bytes result sent to driver
19/06/20 09:19:30 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/06/20 09:19:30 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
